{
  "file_name": "state_result_101.json",
  "conversion_timestamp": "2025-07-16T20:30:25.723572",
  "data": {
    "messages": [
      {
        "content": "本地化部署deepseek r1 671B int4量化版本，我有8张l40s，每张48G显存，能否进行正常部署。正常部署的话，能支撑多少用户并发",
        "additional_kwargs": {},
        "response_metadata": {},
        "type": "human",
        "name": null,
        "id": "0eac683e-632b-4cce-8c93-2f4755e5e471",
        "example": false
      },
      {
        "content": "Yes, deploying the INT4 quantized version of DeepSeek R1 671B on your 8 L40s GPUs, each with 48GB of VRAM, is feasible, but the number of concurrent users you can support depends on several factors.\n\n**Memory Considerations:**\n\nThe full DeepSeek-R1 (671B) model requires substantial VRAM, approximately 1,500+ GB without quantization [dev](https://vertexaisearch.cloud.google.com/id/2-1]. INT4 quantization is crucial to reduce the memory footprint [dev](https://vertexaisearch.cloud.google.com/id/2-1), potentially by 8x compared to FP32 [dev](https://vertexaisearch.cloud.google.com/id/2-1). Even with INT4 quantization, the model might require more than the combined 384GB VRAM (8 GPUs x 48GB) [dev](https://vertexaisearch.cloud.google.com/id/2-1]. Techniques like CPU offloading or model parallelism might be necessary.\n\n**Estimating Concurrent Users:**\n\nGiven the L40S specifications, a rough estimate might place the 8x L40s system at around 1,500 to 2,500 tokens/second [runpod](https://vertexaisearch.cloud.google.com/id/2-7) [computeprices](https://vertexaisearch.cloud.google.com/id/2-8]. Assuming a minimum generation speed of 10 tokens/second per user, the system might support **150 to 250 concurrent users**.\n\n**Factors Affecting Concurrency:**\n\n*   **Context Length:** Longer context lengths require more memory and processing power, reducing the number of concurrent users.\n*   **Token Generation Speed:** The desired token generation speed per user will impact the overall throughput and concurrency.\n*   **Workload Characteristics:** The complexity of the queries and the specific tasks being performed will influence resource utilization.\n*   **Quantization Method:** INT4 quantization can cause more severe reasoning quality degradation and affects accuracy, especially in mathematical calculations, complex logical reasoning, and multi-step inference tasks [theriseunion](https://vertexaisearch.cloud.google.com/id/0-2) [theriseunion](https://vertexaisearch.cloud.google.com/id/0-5].\n\n**Optimization Techniques:**\n\nTo maximize concurrent users, consider these optimization techniques:\n\n*   **Inference Optimization Frameworks:** Use frameworks like vLLM, TensorRT-LLM, or SGLang to improve inference performance [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Tensor Parallelism:** Split the model across multiple GPUs for efficient memory utilization and computation [amazon](https://vertexaisearch.cloud.google.com/id/2-10).\n*   **CPU Offloading:** Offload some layers or computations to the CPU if GPU memory is insufficient [runpod](https://vertexaisearch.cloud.google.com/id/2-7].\n*   **Paged Attention:** Use efficient management of the KV cache [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Continuous Batching:** Process multiple requests in parallel to improve throughput [dev](https://vertexaisearch.cloud.google.com/id/2-1) [amazon](https://vertexaisearch.cloud.google.com/id/2-10].\n\n**Important Considerations:**\n\n*   **Benchmarking:** It is essential to benchmark the system with a representative workload to determine the actual concurrency it can support [huggingface](https://vertexaisearch.cloud.google.com/id/2-14].\n*   **Memory Bandwidth:** Insufficient memory bandwidth can become a bottleneck when inferencing large models across multiple GPUs [theriseunion](https://vertexaisearch.cloud.google.com/id/2-11) [massedcompute](https://vertexaisearch.cloud.google.com/id/2-6) [runpod](https://vertexaisearch.cloud.google.com/id/2-7].\n*   **Inter-GPU Communication:** High-speed interconnects (like NVLink) are crucial for efficient parameter synchronization and KV cache sharing between GPUs [theriseunion](https://vertexaisearch.cloud.google.com/id/2-11) [nvidia](https://vertexaisearch.cloud.google.com/id/2-0].\n\n**Disclaimer:**\n\nThe estimated number of concurrent users (150-250) is a rough approximation. Actual performance can vary significantly based on the specific implementation, optimization techniques used, and workload characteristics.",
        "additional_kwargs": {},
        "response_metadata": {},
        "type": "ai",
        "name": null,
        "id": "981cc691-20ea-4261-bbe7-12053653a965",
        "example": false,
        "tool_calls": [],
        "invalid_tool_calls": [],
        "usage_metadata": null
      }
    ],
    "search_query": [
      "deepseek r1 671B int4 quantization L40s 48GB deployment",
      "deepseek r1 671B int4 L40s concurrent users",
      "Given a system with 8 L40s GPUs (48GB VRAM each), what is the estimated number of concurrent users DeepSeek R1 671B INT4 can support, assuming a context length of 8k tokens and a minimum generation speed of 10 tokens/second per user? Please provide details on the memory management techniques and specific configurations required to achieve this concurrency, as well as potential bottlenecks and optimizations."
    ],
    "web_research_result": [
      "The DeepSeek R1 671B model is a large language model (LLM) designed for reasoning, but its size presents deployment challenges [quickchat](https://vertexaisearch.cloud.google.com/id/0-0) [theriseunion](https://vertexaisearch.cloud.google.com/id/0-1) [theriseunion](https://vertexaisearch.cloud.google.com/id/0-2). Quantization, a technique to reduce the model's memory footprint, is crucial for deploying it on more accessible hardware [arxiv](https://vertexaisearch.cloud.google.com/id/0-3) [arxiv](https://vertexaisearch.cloud.google.com/id/0-4). Here's a breakdown of deploying DeepSeek R1 671B with INT4 quantization on L40s 48GB GPUs:\n\n**1. Hardware and Cost Considerations:**\n\n*   **High Infrastructure Requirements:** DeepSeek R1 and V3 are approximately 400GB in size, requiring substantial infrastructure [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n*   **Quantization Benefits:** Quantization reduces the model size; INT4 quantization can reduce the model size by 75% [theriseunion](https://vertexaisearch.cloud.google.com/id/0-2).\n*   **GPU Options:**\n    *   **High-end:** Running the full-scale model requires 8xA100 GPUs, costing $30,000 per month on Google Cloud Platform (GCP) [quickchat](https://vertexaisearch.cloud.google.com/id/0-0). Even with quantization to 131GB, 2xH100 80GB GPUs are needed, costing $7,000 per month on GCP [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n    *   **Lower-cost:** A Hetzner setup with 512GB RAM + RTX 6000 Ada 48GB VRAM costs $1,000 per month, but performance is significantly slower [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n*   **Local Deployment:** Some users have run DeepSeek on 8 Mac Minis, costing $20,000, but performance was slow [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n*   **Cost-Effectiveness:** DeepSeek proves that high-quality AI doesn't have to be expensive, and the cost of AI is dropping fast [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n\n**2. Quantization and Performance:**\n\n*   **INT4 Quantization:** Using INT4 quantization can reduce the memory cost of DeepSeek-R1's model weights to about 370GB, potentially supporting single-machine deployment [arxiv](https://vertexaisearch.cloud.google.com/id/0-3) [arxiv](https://vertexaisearch.cloud.google.com/id/0-4).\n*   **Accuracy Trade-off:** INT4 quantization can cause more severe reasoning quality degradation and affects accuracy, especially in mathematical calculations, complex logical reasoning, and multi-step inference tasks [theriseunion](https://vertexaisearch.cloud.google.com/id/0-2) [theriseunion](https://vertexaisearch.cloud.google.com/id/0-5).\n*   **Performance Recovery:** Quantized DeepSeek models retain strong performance, with 4-bit quantization results often comparable to FP8 in many scenarios [arxiv](https://vertexaisearch.cloud.google.com/id/0-3) [arxiv](https://vertexaisearch.cloud.google.com/id/0-4).\n*   **Inference Speed:** Quantized reasoning LLMs perform strongly on challenging benchmarks while delivering substantial inference speedups [redhat](https://vertexaisearch.cloud.google.com/id/0-6).\n\n**3. Deployment Strategies and Considerations:**\n\n*   **Single-Machine Deployment:** Hosting the full version of DeepSeek-V3 or DeepSeek-R1 on a single machine is appealing due to its simplicity and relatively low cost [arxiv](https://vertexaisearch.cloud.google.com/id/0-4) [arxiv](https://vertexaisearch.cloud.google.com/id/0-3).\n*   **Offloading Techniques:** Due to the large size of DeepSeek R1 and V3, offloading techniques using tools like Ollama can be employed. This involves storing part of the model in system RAM and dynamically shifting active layers to GPU VRAM [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n*   **Hardware for Offloading:** Even with offloading, a high-memory server is needed, such as one with 512GB of RAM and an NVIDIA L4 GPU (24GB VRAM) or a Hetzner's 512GB RAM + RTX 6000 Ada 48GB VRAM setup [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n*   **NVIDIA Blackwell GPUs:** A single NVIDIA DGX system with eight NVIDIA Blackwell GPUs can achieve over 250 tokens per second per user or a maximum throughput of over 30,000 tokens per second on the DeepSeek-R1 model [nvidia](https://vertexaisearch.cloud.google.com/id/0-7).\n*   **Consumer Hardware:** While optimized for NVIDIA H800 GPUs, DeepSeek R1's efficient design lowers hardware requirements compared to GPT-4. Running on consumer GPUs is still challenging but more feasible with quantization and pruning [medium](https://vertexaisearch.cloud.google.com/id/0-8).\n*   **Local Gaming Rig:** It is possible to achieve over 2 tokens/second without a GPU on a local gaming rig by using dynamic quantization and mmap() the model files off of a fast NVMe SSD [reddit](https://vertexaisearch.cloud.google.com/id/0-9).\n\n**4. Model Details and Capabilities:**\n\n*   **Reasoning Focus:** DeepSeek R1 is built for reasoning and uses inference-time scaling techniques, which may result in longer response times but more structured and logical answers [quickchat](https://vertexaisearch.cloud.google.com/id/0-0).\n*   **MoE Architecture:** DeepSeek R1 has a Mixture of Experts (MoE) architecture, activating only 37 billion parameters per token, which lowers computational costs and speeds up inference [medium](https://vertexaisearch.cloud.google.com/id/0-8).\n*   **Context Window:** It can maintain context over 128,000 tokens, making it suitable for tasks involving lengthy documents [medium](https://vertexaisearch.cloud.google.com/id/0-8).\n*   **Distilled Models:** DeepSeek-R1 distilled models are fine-tuned versions of open-source models, inheriting DeepSeek's reasoning capabilities while being more efficient to self-host [linuxblog](https://vertexaisearch.cloud.google.com/id/0-10).\n\n**5. Potential Issues:**\n\n*   **\"Reduced Intelligence\":** Many domestic AI accelerator card DeepSeek deployments suffer from \"reduced intelligence\" issues [theriseunion](https://vertexaisearch.cloud.google.com/id/0-5).\n*   **Quantization Errors:** Quantization errors can affect inference accuracy, especially in mathematical calculations, complex logical reasoning, and multi-step inference tasks, potentially degrading performance [theriseunion](https://vertexaisearch.cloud.google.com/id/0-2).\n\nIn summary, deploying DeepSeek R1 671B with INT4 quantization on L40s 48GB GPUs is possible but requires careful consideration of hardware requirements, cost, and the trade-offs between memory usage and accuracy. While quantization enables deployment on less powerful hardware, it's essential to evaluate the impact on performance and ensure it meets the specific requirements of the intended application.\n",
      "It appears the user is asking about the DeepSeek R1 671B model, specifically regarding concurrent users when running the int4 quantized version on L40s GPUs. Here's a summary of what the search results provide:\n\n**DeepSeek R1 671B Overview:**\n\n*   **Architecture:** DeepSeek R1 utilizes a Mixture of Experts (MoE) architecture [dev](https://vertexaisearch.cloud.google.com/id/1-0) [deepseek-r1](https://vertexaisearch.cloud.google.com/id/1-1). It has a total of 671 billion parameters, with 37 billion activated per token [textcortex](https://vertexaisearch.cloud.google.com/id/1-2) [dev](https://vertexaisearch.cloud.google.com/id/1-0) [deepseek-r1](https://vertexaisearch.cloud.google.com/id/1-1). It supports a context length of 128K tokens [deepseek-r1](https://vertexaisearch.cloud.google.com/id/1-1) [textcortex](https://vertexaisearch.cloud.google.com/id/1-2) [nvidia](https://vertexaisearch.cloud.google.com/id/1-3) [dev](https://vertexaisearch.cloud.google.com/id/1-0).\n*   **Performance:** DeepSeek R1 demonstrates performance comparable to OpenAI's models in math, code, and reasoning tasks [textcortex](https://vertexaisearch.cloud.google.com/id/1-2) [huggingface](https://vertexaisearch.cloud.google.com/id/1-4) [deepseek-r1](https://vertexaisearch.cloud.google.com/id/1-1). It achieves high scores in benchmarks like MATH-500 (97.3%), Codeforces (96.3% percentile), and AIME 2024 (79.8%) [deepseek-r1](https://vertexaisearch.cloud.google.com/id/1-1) [textcortex](https://vertexaisearch.cloud.google.com/id/1-2).\n*   **Inference Speed:** On a single NVIDIA DGX system with eight NVIDIA Blackwell GPUs, DeepSeek-R1 671B can achieve over 250 tokens per second per user, or a maximum throughput of over 30,000 tokens per second [nvidia](https://vertexaisearch.cloud.google.com/id/1-5). On a single NVIDIA HGX H200 system, the DeepSeek-R1 NIM microservice can deliver up to 3,872 tokens per second [nvidia](https://vertexaisearch.cloud.google.com/id/1-3).\n*   **Quantization:** DeepSeek uses native FP8 for training and inference [theriseunion](https://vertexaisearch.cloud.google.com/id/1-6) [theriseunion](https://vertexaisearch.cloud.google.com/id/1-7) [theriseunion](https://vertexaisearch.cloud.google.com/id/1-8) [fireworks](https://vertexaisearch.cloud.google.com/id/1-9) [theriseunion](https://vertexaisearch.cloud.google.com/id/1-10). For GPUs that do not support FP8, the model can be converted to BF16, though this doubles the memory usage [theriseunion](https://vertexaisearch.cloud.google.com/id/1-10) [theriseunion](https://vertexaisearch.cloud.google.com/id/1-8) [theriseunion](https://vertexaisearch.cloud.google.com/id/1-6). Quantization to INT4 reduces memory usage but can impact accuracy [theriseunion](https://vertexaisearch.cloud.google.com/id/1-8) [dev](https://vertexaisearch.cloud.google.com/id/1-0).\n*   **Hardware Requirements:** Running the full DeepSeek-R1 671B model requires substantial resources [apxml](https://vertexaisearch.cloud.google.com/id/1-11). A multi-GPU setup with a minimum of 16x NVIDIA A100 80GB GPUs is recommended [dev](https://vertexaisearch.cloud.google.com/id/1-0) [apxml](https://vertexaisearch.cloud.google.com/id/1-11). VRAM requirements are approximately 1,500+ GB without quantization [dev](https://vertexaisearch.cloud.google.com/id/1-0).\n\n**DeepSeek R1 671B int4 on L40s:**\n\n*   One source mentions running DeepSeek R1 671B on 4 nodes of L40S GPUs, with 8 GPUs per node [github](https://vertexaisearch.cloud.google.com/id/1-12). However, this source discusses a bug related to FlashMLA and doesn't provide specific details on concurrent users or performance [github](https://vertexaisearch.cloud.google.com/id/1-12).\n*   L40S GPUs are mentioned as suitable for DeepSeek inference, but primarily in the context of comparing them to other GPUs with FP8 support [theriseunion](https://vertexaisearch.cloud.google.com/id/1-10) [stackscale](https://vertexaisearch.cloud.google.com/id/1-13).\n*   It is possible to run a Q4_K_M version of DeepSeek-Coder-V3/R1 671B with 14GB VRAM and 382GB DRAM using KTransformers [github](https://vertexaisearch.cloud.google.com/id/1-14).\n\n**Concurrent User Capacity:**\n\n*   The number of concurrent users depends heavily on the hardware configuration, context length, and desired token generation speed.\n*   A single NVIDIA DGX system with eight NVIDIA Blackwell GPUs can achieve over 250 tokens per second *per user* [nvidia](https://vertexaisearch.cloud.google.com/id/1-5).\n*   One user reported experimenting with up to 8 concurrent slots inferencing on a gaming rig with 96GB RAM + 24GB VRAM, achieving 1~2 tokens/sec with a 2k~16k context using a dynamic quant [reddit](https://vertexaisearch.cloud.google.com/id/1-15).\n*   A mid-range deployment with an NVIDIA RTX A6000 (48GB VRAM) running DeepSeek-R1-Distill-Llama-8B achieved 1,600 tokens/second with 50 concurrent requests and 2,865 tokens/second with 100 concurrent requests [dev](https://vertexaisearch.cloud.google.com/id/1-0).\n\n**Limitations and Considerations:**\n\n*   **Memory Capacity (VRAM):** Insufficient memory can prevent models from loading or cause low operational efficiency [theriseunion](https://vertexaisearch.cloud.google.com/id/1-7) [theriseunion](https://vertexaisearch.cloud.google.com/id/1-8).\n*   **SSD Wear:** Frequent writes (e.g., swapping layers) could degrade SSD lifespan over years of heavy use, but this is negligible for most users [reddit](https://vertexaisearch.cloud.google.com/id/1-15).\n*   **Thermals:** Sustained high token generation rates may push the thermal limits of the hardware [reddit](https://vertexaisearch.cloud.google.com/id/1-15).\n*   **Quantization:** While quantization reduces memory footprint, it can also impact accuracy, especially in tasks requiring mathematical calculations or complex reasoning [theriseunion](https://vertexaisearch.cloud.google.com/id/1-8).\n\n**In summary:** While the search results confirm that DeepSeek R1 671B can run on L40s GPUs, a precise number for concurrent users for an int4 quantized version isn't explicitly stated. The concurrent user capacity will depend on the specific hardware configuration (number of GPUs, memory, etc.), the context length being used, and the acceptable token generation speed for the application.\n",
      "It's challenging to provide a precise number of concurrent users for DeepSeek R1 671B INT4 on a system with 8 L40s GPUs (48GB VRAM each) without specific benchmarking data for that exact configuration. However, the search results provide valuable insights for estimating and optimizing such a deployment.\n\n**Memory Capacity and Model Size:**\n\n*   The DeepSeek R1 671B model is a large Mixture of Experts (MoE) model [nvidia](https://vertexaisearch.cloud.google.com/id/2-0) [dev](https://vertexaisearch.cloud.google.com/id/2-1). It has 671 billion parameters, with 37 billion activated per token [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   The full DeepSeek-R1 (671B) model requires substantial VRAM, approximately 1,500+ GB without quantization [dev](https://vertexaisearch.cloud.google.com/id/2-1). With FP8, it requires approximately 700GB for parameter storage [theriseunion](https://vertexaisearch.cloud.google.com/id/2-2) [theriseunion](https://vertexaisearch.cloud.google.com/id/2-3).\n*   The NVIDIA L40S GPU has 48GB of VRAM [lenovo](https://vertexaisearch.cloud.google.com/id/2-4) [itglobal](https://vertexaisearch.cloud.google.com/id/2-5) [massedcompute](https://vertexaisearch.cloud.google.com/id/2-6) [runpod](https://vertexaisearch.cloud.google.com/id/2-7) [computeprices](https://vertexaisearch.cloud.google.com/id/2-8).\n*   INT4 quantization can reduce memory requirements by approximately 8x compared to FP32 [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n\n**Inference Performance and Throughput:**\n\n*   A single NVIDIA DGX system with eight NVIDIA Blackwell GPUs can achieve over 250 tokens per second per user or a maximum throughput of over 30,000 tokens per second on the DeepSeek-R1 671B model [nvidia](https://vertexaisearch.cloud.google.com/id/2-9).\n*   An NVIDIA NIM microservice can deliver up to 3,872 tokens per second on a single NVIDIA HGX H200 system [nvidia](https://vertexaisearch.cloud.google.com/id/2-0).\n*   8x NVIDIA H200 GPUs can achieve a throughput of ~3,800 tokens/second with the DeepSeek-R1 (671B) model using the SGLang inference engine [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   8x NVIDIA H100 GPUs with 4-bit quantization can achieve a throughput of ~2,500 tokens/second with DeepSeek-R1 (671B) using vLLM 0.7 [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   The L40S GPU is well-suited for LLM inference due to its high memory capacity [runpod](https://vertexaisearch.cloud.google.com/id/2-7). It can host large models entirely in GPU memory, reducing the need for model sharding or CPU offloading [runpod](https://vertexaisearch.cloud.google.com/id/2-7).\n*   The L40S has 18,176 CUDA cores and high clock speeds, delivering good compute [runpod](https://vertexaisearch.cloud.google.com/id/2-7). It also provides ~864 GB/s memory bandwidth [massedcompute](https://vertexaisearch.cloud.google.com/id/2-6) [runpod](https://vertexaisearch.cloud.google.com/id/2-7) [computeprices](https://vertexaisearch.cloud.google.com/id/2-8).\n\n**Estimating Concurrent Users:**\n\n1.  **Quantization:** Using INT4 quantization is crucial to fit the model within the available VRAM of the 8 L40s GPUs [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n2.  **Memory Considerations:** Even with INT4 quantization, the model might require more than the combined 384GB VRAM (8 GPUs x 48GB) [dev](https://vertexaisearch.cloud.google.com/id/2-1). Techniques like CPU offloading or model parallelism might be necessary.\n3.  **Throughput per User:** Assuming a minimum generation speed of 10 tokens/second per user, the system needs to deliver at least that many tokens per second for each concurrent user [runpod](https://vertexaisearch.cloud.google.com/id/2-7).\n4.  **Scaling from H100/H200:** Given that 8x H100 GPUs (with INT4) can achieve ~2,500 tokens/second and 8x H200 GPUs can achieve ~3,800 tokens/second, we can estimate the L40s performance. The L40S has less compute power and memory bandwidth than H100/H200 [runpod](https://vertexaisearch.cloud.google.com/id/2-7).\n5.  **Estimating L40s Performance:** A rough estimate, considering the L40S specifications, might place the 8x L40s system at around 1,500 to 2,500 tokens/second [runpod](https://vertexaisearch.cloud.google.com/id/2-7) [computeprices](https://vertexaisearch.cloud.google.com/id/2-8).\n6.  **Concurrent User Calculation:** Based on the estimated throughput of 1,500 to 2,500 tokens/second and a requirement of 10 tokens/second per user, the system might support **150 to 250 concurrent users**.\n\n**Memory Management Techniques and Configurations:**\n\n*   **Quantization:** Using INT4 or even lower precision quantization (like 1.5-bit dynamic quantization) is essential to reduce the memory footprint [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Inference Optimization Frameworks:** Using frameworks like vLLM, TensorRT-LLM, or SGLang can significantly improve inference performance [dev](https://vertexaisearch.cloud.google.com/id/2-1). vLLM optimizes attention computation and manages the KV cache efficiently [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Tensor Parallelism:** Splitting the model across multiple GPUs for efficient memory utilization and computation [amazon](https://vertexaisearch.cloud.google.com/id/2-10).\n*   **CPU Offloading:** Offloading some layers or computations to the CPU if the GPU memory is insufficient [runpod](https://vertexaisearch.cloud.google.com/id/2-7).\n*   **Paged Attention:** Efficient management of the KV cache [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Continuous Batching:** Processing multiple requests in parallel to improve throughput [dev](https://vertexaisearch.cloud.google.com/id/2-1) [amazon](https://vertexaisearch.cloud.google.com/id/2-10).\n\n**Potential Bottlenecks and Optimizations:**\n\n*   **Memory Bandwidth:** Insufficient memory bandwidth can become a bottleneck when inferencing large models across multiple GPUs [theriseunion](https://vertexaisearch.cloud.google.com/id/2-11) [massedcompute](https://vertexaisearch.cloud.google.com/id/2-6) [runpod](https://vertexaisearch.cloud.google.com/id/2-7).\n*   **Inter-GPU Communication:** High-speed interconnects (like NVLink) are crucial for efficient parameter synchronization and KV cache sharing between GPUs [theriseunion](https://vertexaisearch.cloud.google.com/id/2-11) [nvidia](https://vertexaisearch.cloud.google.com/id/2-0).\n*   **Attention Mechanism:** Optimizing attention computation (e.g., using FlashAttention) can lead to faster inference [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **FP8 Support:** Using FP8 precision, if supported, can improve computational efficiency and inference accuracy [theriseunion](https://vertexaisearch.cloud.google.com/id/2-2) [lenovo](https://vertexaisearch.cloud.google.com/id/2-4) [itglobal](https://vertexaisearch.cloud.google.com/id/2-5) [runpod](https://vertexaisearch.cloud.google.com/id/2-7).\n*   **Model Distillation:** Consider using distilled versions of DeepSeek-R1, which have reduced parameter counts and lower hardware requirements [dev](https://vertexaisearch.cloud.google.com/id/2-12) [dev](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Load Balancing:** For MoE models, efficient load balancing across experts is crucial [github](https://vertexaisearch.cloud.google.com/id/2-13).\n\n**Disclaimer:**\n\nThe estimated number of concurrent users (150-250) is a rough approximation. Actual performance can vary significantly based on the specific implementation, optimization techniques used, and workload characteristics. Benchmarking the system with a representative workload is essential to determine the actual concurrency it can support [huggingface](https://vertexaisearch.cloud.google.com/id/2-14).\n"
    ],
    "sources_gathered": [
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH0l26Fq-ghWeTh1wV-NhqHVSajng37BGP3dgNk2nJwJajfvCoLtwJLMJL7I-8yQb8xowOkqpO918ZaAsXzoQNnef-rXUh8_U1qZ67UUzxZEua_h1VBwevyd6QHGsrNAhTSbjhWNi8sm6XdadJyDHzha0GrkRQrQx_jevX_Rzkzft6ubj6PoQ=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHqrAA24VsGm6tHi-WectYO-q8LcsfjB00oREUudTgzonq2qr0N-HVUnvadrpmmeM51SYMuwgoP9KXQsqqtu3lcsT6sjzfeb5UwLAIiQYRP1RCCTf5g-Mwiw5doevFh51z_RQc_AFUKtT0v3n-Y4-JGjbssV2bYO9oKrXk="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXT9IbtXzoXN0e5hsrwHvyU8psd8DATFANFvt8v2xMUKxW_ZNblePkc2NyUO6R6GkPPXeuAJNY31j8XIQooAfh-ziWxWhBUH_RvXy2YPM4qkF5oNqzwRrCgpJgOh4g"
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGGJOniTNk1GlI9OSGzxnVXrUoAznQakFBFU-9-fkn4lt16JnIh5CkukIoWBJgUiQ4GO6xJMgKVhBeBUjlxJCTUFoyZSDoN8b3IsCd8E9wsm0ccU92BviKnmN"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHqrAA24VsGm6tHi-WectYO-q8LcsfjB00oREUudTgzonq2qr0N-HVUnvadrpmmeM51SYMuwgoP9KXQsqqtu3lcsT6sjzfeb5UwLAIiQYRP1RCCTf5g-Mwiw5doevFh51z_RQc_AFUKtT0v3n-Y4-JGjbssV2bYO9oKrXk="
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXT9IbtXzoXN0e5hsrwHvyU8psd8DATFANFvt8v2xMUKxW_ZNblePkc2NyUO6R6GkPPXeuAJNY31j8XIQooAfh-ziWxWhBUH_RvXy2YPM4qkF5oNqzwRrCgpJgOh4g"
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGGJOniTNk1GlI9OSGzxnVXrUoAznQakFBFU-9-fkn4lt16JnIh5CkukIoWBJgUiQ4GO6xJMgKVhBeBUjlxJCTUFoyZSDoN8b3IsCd8E9wsm0ccU92BviKnmN"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHqrAA24VsGm6tHi-WectYO-q8LcsfjB00oREUudTgzonq2qr0N-HVUnvadrpmmeM51SYMuwgoP9KXQsqqtu3lcsT6sjzfeb5UwLAIiQYRP1RCCTf5g-Mwiw5doevFh51z_RQc_AFUKtT0v3n-Y4-JGjbssV2bYO9oKrXk="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFqkchGyiuIyo7RI2vQMZ74ftiTUm1noFsbUPPYU5EhM8brPVK-zpyhJ7lw_MMG-lALKl1tOB_i1d5F2CCHqzfynlXNJ27wLyeRfVN4-s8x4HLJal6sbYsuSSOl5tEVQ739ZU-Ys-JSNAuZbjHOaMfyyXhElDu3S9ascVqMlx4="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXT9IbtXzoXN0e5hsrwHvyU8psd8DATFANFvt8v2xMUKxW_ZNblePkc2NyUO6R6GkPPXeuAJNY31j8XIQooAfh-ziWxWhBUH_RvXy2YPM4qkF5oNqzwRrCgpJgOh4g"
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGGJOniTNk1GlI9OSGzxnVXrUoAznQakFBFU-9-fkn4lt16JnIh5CkukIoWBJgUiQ4GO6xJMgKVhBeBUjlxJCTUFoyZSDoN8b3IsCd8E9wsm0ccU92BviKnmN"
      },
      {
        "label": "redhat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGjVAWSNPpIsFfayvFQdge3_PWCVe_kNkGOJ2pYfnEO89-VE54Pog4R6-_sG6xWorA9jlwvzkutBDhyQ06EWckFEHPL22rDuXQkwhYedZyG_RRAhV0xAe3cnm4pEMUyu-0JPGRZMgzspM_ZpvIXrj6RnwydjCFcOaVqc52uTISbKk4Y__eP3oFtArGxUZ0K5Zvs7smMtn3MeRbbY16QSwWCYhSrCQ=="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGGJOniTNk1GlI9OSGzxnVXrUoAznQakFBFU-9-fkn4lt16JnIh5CkukIoWBJgUiQ4GO6xJMgKVhBeBUjlxJCTUFoyZSDoN8b3IsCd8E9wsm0ccU92BviKnmN"
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXT9IbtXzoXN0e5hsrwHvyU8psd8DATFANFvt8v2xMUKxW_ZNblePkc2NyUO6R6GkPPXeuAJNY31j8XIQooAfh-ziWxWhBUH_RvXy2YPM4qkF5oNqzwRrCgpJgOh4g"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH7y8y4LWWOPwnzh7JacPP4wIsVZiw3feGqHhM9WyJKkPh4leNvoWpbruPl96Un8tgjOjoIU-TRLDfVac0taNl91-WdW5_2gjH5fOiCm4wH-iZwKYw8svXvo9165yEEGsU02VyOroulFjrQhal9BybBpwAej4ZynWRP3lCdbXXfFpnP8n53ZCrPgyNvF65HkIy9fIx3zZbyNgAFzZZ1djARjZ8Fepkw"
      },
      {
        "label": "medium",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFY5QK1R1nJrrNkXdjBYN1IobfZZoJ-XjA42oAp2OTzl9-mqHFQ4SShm4bcrTLUOqY1BgQSxyIrZcxyFn-qI2YqPWiudwgvp1lgokWTJkZB9h_SuIFzBrPFAEDx1BbT6DctfxYd_ng-PB4iWkTbPruj93xGaE9KaLYKxlCot-QrX_plXrur3IL55A8Kwg0u6xxzPL82XWajG9BmjoXgGAud4c5xQQ=="
      },
      {
        "label": "reddit",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-9",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH-aUJdQTe8vytS605cecRpvdZAelEJrM9o9SxbjIyK9stJK-GziJ6kolg0L7w7VFldBPGKGpIoTUm0qebBDU9S0xygKp03Fgw41IeEpfDJ71UfxI_VI62S2xDhKaoTG1BcauTREYOE40C6h2_9ZaW8uvpB3vy-dYrQLW7fplGx81OvmbZVun3drz-TaOJ8KxD_dVTUH3D9UkXWD-0pUQ=="
      },
      {
        "label": "quickchat",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnePK34Y3dGO3Ybw1wTeyYeb_cOVyzFSbljTDRNIsimG7E_dnVOak5TqTxU_e45JhpXN2orCkaVy2WnOvEfBChmgQM7rZMj3siPSmq56ciAa88S97nmU3_KZC1vMvuh9tG6aLWIaD6"
      },
      {
        "label": "medium",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFY5QK1R1nJrrNkXdjBYN1IobfZZoJ-XjA42oAp2OTzl9-mqHFQ4SShm4bcrTLUOqY1BgQSxyIrZcxyFn-qI2YqPWiudwgvp1lgokWTJkZB9h_SuIFzBrPFAEDx1BbT6DctfxYd_ng-PB4iWkTbPruj93xGaE9KaLYKxlCot-QrX_plXrur3IL55A8Kwg0u6xxzPL82XWajG9BmjoXgGAud4c5xQQ=="
      },
      {
        "label": "medium",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFY5QK1R1nJrrNkXdjBYN1IobfZZoJ-XjA42oAp2OTzl9-mqHFQ4SShm4bcrTLUOqY1BgQSxyIrZcxyFn-qI2YqPWiudwgvp1lgokWTJkZB9h_SuIFzBrPFAEDx1BbT6DctfxYd_ng-PB4iWkTbPruj93xGaE9KaLYKxlCot-QrX_plXrur3IL55A8Kwg0u6xxzPL82XWajG9BmjoXgGAud4c5xQQ=="
      },
      {
        "label": "linuxblog",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGRVMHE0dsOb-nqoYTuPwU-oipXpB-IM_f_wCBMlVLwwHEzzOCZvOuLnlSC_5kbzv_cPKh-DW-NcG2f5j23Agnj2tjXvGzDW7jMThchJL1N0ENMHnn52qofbmAEiu0rqJLBgCV7M-BfSFA="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFqkchGyiuIyo7RI2vQMZ74ftiTUm1noFsbUPPYU5EhM8brPVK-zpyhJ7lw_MMG-lALKl1tOB_i1d5F2CCHqzfynlXNJ27wLyeRfVN4-s8x4HLJal6sbYsuSSOl5tEVQ739ZU-Ys-JSNAuZbjHOaMfyyXhElDu3S9ascVqMlx4="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHqrAA24VsGm6tHi-WectYO-q8LcsfjB00oREUudTgzonq2qr0N-HVUnvadrpmmeM51SYMuwgoP9KXQsqqtu3lcsT6sjzfeb5UwLAIiQYRP1RCCTf5g-Mwiw5doevFh51z_RQc_AFUKtT0v3n-Y4-JGjbssV2bYO9oKrXk="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "deepseek-r1",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHbxO4LuMCJ5DSdX2vhqJPeW9GnyBqDu1B493ruUB5fwJWfSF1sVOJFV4KhTl2QaU5GrDRUPyxYdf6yRusdx50lPl0oQJ6g4mTdZVjiSKfQKwQz3w=="
      },
      {
        "label": "textcortex",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPLH6CGs_2Od72XB2bCvA0WLFuGB3X-n1Jl3n8nH6PJTOiYJapGJ0r7ZDaiaTEgeXtNb8jC5TDK4XXZ07cR1rODFv5TxVWic0Olf8Ul1UPt5lBPxTdSIyjLMlg_sNmTGbxFA7y9OdGrZw="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "deepseek-r1",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHbxO4LuMCJ5DSdX2vhqJPeW9GnyBqDu1B493ruUB5fwJWfSF1sVOJFV4KhTl2QaU5GrDRUPyxYdf6yRusdx50lPl0oQJ6g4mTdZVjiSKfQKwQz3w=="
      },
      {
        "label": "deepseek-r1",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHbxO4LuMCJ5DSdX2vhqJPeW9GnyBqDu1B493ruUB5fwJWfSF1sVOJFV4KhTl2QaU5GrDRUPyxYdf6yRusdx50lPl0oQJ6g4mTdZVjiSKfQKwQz3w=="
      },
      {
        "label": "textcortex",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPLH6CGs_2Od72XB2bCvA0WLFuGB3X-n1Jl3n8nH6PJTOiYJapGJ0r7ZDaiaTEgeXtNb8jC5TDK4XXZ07cR1rODFv5TxVWic0Olf8Ul1UPt5lBPxTdSIyjLMlg_sNmTGbxFA7y9OdGrZw="
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFMcf_okQSawXshpsicU0pzMAt9t8BUXCA0BnVKY_UwU7I_hhecckOCDp2fnNbBK4ZynJxOwH1nWa1_Ztf4n-I8cvPKYRB-o0VgsJO0eVm8Bx9YTq89KsgiSYRlxqljXcbg3xLFd4CK5agUw_JFTnN-dP28nNOX"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "textcortex",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPLH6CGs_2Od72XB2bCvA0WLFuGB3X-n1Jl3n8nH6PJTOiYJapGJ0r7ZDaiaTEgeXtNb8jC5TDK4XXZ07cR1rODFv5TxVWic0Olf8Ul1UPt5lBPxTdSIyjLMlg_sNmTGbxFA7y9OdGrZw="
      },
      {
        "label": "huggingface",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF8yQWE6xkB5_g6b1WmtHZpQqZMr2-Suu1V0QivQHPa3MsaOtXZ204y8lNxQ1eed84XpQWklTURqgKIOsT7a4pyVJFWaQp8vhr3UzMAgsg9FK5MiVF3s1SqUhaVYsu_6Cb2clTfvFLDl6I="
      },
      {
        "label": "deepseek-r1",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHbxO4LuMCJ5DSdX2vhqJPeW9GnyBqDu1B493ruUB5fwJWfSF1sVOJFV4KhTl2QaU5GrDRUPyxYdf6yRusdx50lPl0oQJ6g4mTdZVjiSKfQKwQz3w=="
      },
      {
        "label": "deepseek-r1",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHbxO4LuMCJ5DSdX2vhqJPeW9GnyBqDu1B493ruUB5fwJWfSF1sVOJFV4KhTl2QaU5GrDRUPyxYdf6yRusdx50lPl0oQJ6g4mTdZVjiSKfQKwQz3w=="
      },
      {
        "label": "textcortex",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPLH6CGs_2Od72XB2bCvA0WLFuGB3X-n1Jl3n8nH6PJTOiYJapGJ0r7ZDaiaTEgeXtNb8jC5TDK4XXZ07cR1rODFv5TxVWic0Olf8Ul1UPt5lBPxTdSIyjLMlg_sNmTGbxFA7y9OdGrZw="
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFQQx3RZaGEoaCjGsv9vIe52lpSJoLKnE8uXSDLtpMme_OGQdK6A3-QsEuZ7EC6l0eCYKP40QgtTcPDR-Pa-r4C2qVit-TQiuf47qY1JGfwGMv38BucVNsjk20Y61CnwbPIAxM9G_1u5RGMd6YpdBsclfaGhlHJaZtZ-cOcAQ_5nKxRuOUCV-p7wZ60-vp7OfxGtXGcT6ZfQYSPbw4svA3rSjt6fjZ6"
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFMcf_okQSawXshpsicU0pzMAt9t8BUXCA0BnVKY_UwU7I_hhecckOCDp2fnNbBK4ZynJxOwH1nWa1_Ztf4n-I8cvPKYRB-o0VgsJO0eVm8Bx9YTq89KsgiSYRlxqljXcbg3xLFd4CK5agUw_JFTnN-dP28nNOX"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG636o49Jw73z3f5YBDdG-CsJ5HcPzoBAYVNkoHuQqoVIKoGpE3_JxGeGPOlq-6_ufOO0wvZ7eixwMXZ-izSm1pXJVY4BndS2QjdEYJWeUaqKVX7IxZ4_356W4OdfRhDpIQNBZk7vICMgeK81c3a4F6-clA11Jjul7oswVgFsk="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGQ76W_Md8fHKRDaOZlxT_Kx3y7xBm4_kFQd98bcKuyzuPj6mKbSSxxe4uiHiYYtP0jQYUoxhI03d-2PK4LpdAedgcuqnZQ4Kx4U9WpPHk4m6OT4iilIf0hXP7y4LRl9A9N_w38_JiXwlDUI2AxMMI_XTJs4ycChw1xLo2LSKK_Bl-JQI_CA=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6zgzm1vw0i_SppBNnRLXAKuMlIc0tM-u42kdyKJYStFpuM10aitJa7Sa2uhXMo6l2xhhKeCFU6twEdzJf4ohHy9WNauzAPfEBibWGRG0783xR0lkaAgEuovhaJHnnrRNZl5Db7hMuNtb_d9NeASoj7YR3dF-SC75t8hU="
      },
      {
        "label": "fireworks",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-9",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHUGFIp5ghThvy8Nl8xWyjqGvCAV_Pf1FBMcM9dmm_uk5XrXVMYwXwCc7O7XlTOir_k-cvuSP-OgLP7Qo6oUYv52bTa23Fy68HFQb968Se-aRZtFoU1RpWqV54BrJWBL3lHpvBVO0ZkYQfczY3xrouh"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFkz_jzVPZHaJCs-I-zul4hxt-NgH6iUhrmiafeTRMTEU9t_fBELJLahTVculDC2-gNAIu3p1L-PKenhuzz0n_A7SiO1SgJAHtZHeRNFLBQYKbMYuOQONP9W8c7-MAaNj-3udW41wSSQnCI6i-cv8ewWuaQbznANLtkHSeMFMfmynH1VWXugA2qEw=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFkz_jzVPZHaJCs-I-zul4hxt-NgH6iUhrmiafeTRMTEU9t_fBELJLahTVculDC2-gNAIu3p1L-PKenhuzz0n_A7SiO1SgJAHtZHeRNFLBQYKbMYuOQONP9W8c7-MAaNj-3udW41wSSQnCI6i-cv8ewWuaQbznANLtkHSeMFMfmynH1VWXugA2qEw=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6zgzm1vw0i_SppBNnRLXAKuMlIc0tM-u42kdyKJYStFpuM10aitJa7Sa2uhXMo6l2xhhKeCFU6twEdzJf4ohHy9WNauzAPfEBibWGRG0783xR0lkaAgEuovhaJHnnrRNZl5Db7hMuNtb_d9NeASoj7YR3dF-SC75t8hU="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG636o49Jw73z3f5YBDdG-CsJ5HcPzoBAYVNkoHuQqoVIKoGpE3_JxGeGPOlq-6_ufOO0wvZ7eixwMXZ-izSm1pXJVY4BndS2QjdEYJWeUaqKVX7IxZ4_356W4OdfRhDpIQNBZk7vICMgeK81c3a4F6-clA11Jjul7oswVgFsk="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6zgzm1vw0i_SppBNnRLXAKuMlIc0tM-u42kdyKJYStFpuM10aitJa7Sa2uhXMo6l2xhhKeCFU6twEdzJf4ohHy9WNauzAPfEBibWGRG0783xR0lkaAgEuovhaJHnnrRNZl5Db7hMuNtb_d9NeASoj7YR3dF-SC75t8hU="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "apxml",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHOgsTnErnQLSeq779KZeTLgsCnqS6mMc07ARD355A7Zm1zkXv7wfryQhStr_lp1lp6WY4ndAgUwJzgkTRucWrRQUd2rInAsnuSx2BxzXZ1wS2ARdzuzh0eWaucrklikSBerfXtCFQAEJJcGZ_0gCo="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "apxml",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHOgsTnErnQLSeq779KZeTLgsCnqS6mMc07ARD355A7Zm1zkXv7wfryQhStr_lp1lp6WY4ndAgUwJzgkTRucWrRQUd2rInAsnuSx2BxzXZ1wS2ARdzuzh0eWaucrklikSBerfXtCFQAEJJcGZ_0gCo="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "github",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-12",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFJ7EOJT0jpevGS-me4SsfNoO7e-6Xtew1hDdoSbSYgoacST2uD0uY89ymtXGxZHCnZ6leq9kceGzdXWZYcsACflilD1pFmsQi9IU-icYk4cER_0FzxTDGsOMaUBFWn6tNEn1a1gN6O4MJ18z0="
      },
      {
        "label": "github",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-12",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFJ7EOJT0jpevGS-me4SsfNoO7e-6Xtew1hDdoSbSYgoacST2uD0uY89ymtXGxZHCnZ6leq9kceGzdXWZYcsACflilD1pFmsQi9IU-icYk4cER_0FzxTDGsOMaUBFWn6tNEn1a1gN6O4MJ18z0="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFkz_jzVPZHaJCs-I-zul4hxt-NgH6iUhrmiafeTRMTEU9t_fBELJLahTVculDC2-gNAIu3p1L-PKenhuzz0n_A7SiO1SgJAHtZHeRNFLBQYKbMYuOQONP9W8c7-MAaNj-3udW41wSSQnCI6i-cv8ewWuaQbznANLtkHSeMFMfmynH1VWXugA2qEw=="
      },
      {
        "label": "stackscale",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-13",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFhzAxi0MBoJZMl-uKkm6n12GJlogyPD_R8bmkC28dum0CK52vxRjnURadZ0A3a7paKuqSYVvVmWBs0cVuluB-F50N6l3QUP4yyIqH1bWHaxm2VJEEUAQZ9AyL7upKGPnMCg9l31BdSf3tnBB87_tlprCchsOlsog=="
      },
      {
        "label": "github",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-14",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF9ug5K-InJJuX7yNh2lf0zeSUMYMBi6RCk5id7zx3DNGdWDBck4HoKw0y6pSBATWG_Qe3Tw8RsDLpH1oSGXQ3DxA2nWWN0IiBxAmo7YOAtnuKa_u_bhpWZ4RvamJX1A5dnqULX5fYQr65Wf0r8H6dMDIYECBUejFc2eKUnC97fbyIrK9Q="
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFQQx3RZaGEoaCjGsv9vIe52lpSJoLKnE8uXSDLtpMme_OGQdK6A3-QsEuZ7EC6l0eCYKP40QgtTcPDR-Pa-r4C2qVit-TQiuf47qY1JGfwGMv38BucVNsjk20Y61CnwbPIAxM9G_1u5RGMd6YpdBsclfaGhlHJaZtZ-cOcAQ_5nKxRuOUCV-p7wZ60-vp7OfxGtXGcT6ZfQYSPbw4svA3rSjt6fjZ6"
      },
      {
        "label": "reddit",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-15",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFdhT5Xcc-r-C8oLtJ8LJ2SLGP4GqscoZpIQbKJT95XX5jV8cPiTyi3oWEr98GuegJXCdmp8f_ZWPi8NujXGu82ABjX-LhSlGM9bIofIu-WshnGxDwzy80quYR0N-pF8H4iJQtyaPNnxWh8kdGOuKK-SsCS5f_fh82hmCRp-il-iw1nZXw8kjmo8DC-XQ4sNAKnl_PnXciCPw54cIkFEg=="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_4Jdhc9I9HsQGp-H3hAuv0fu9UfaIF2FmvottOuChMlDDCoSfo1XyF2vuoJYJXQlogSLmCDDTJF1cjhvJcUX5oGIh8ud1Xas0Ru1niv7YH0DX0Oszc4yNPElGPpSBsAv-8Mc5KeuLKy-rkUzZdjUvMiNM6YqNQ7jLqoSwLJqRY_Anrh8uovjTqulHRKMx"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGQ76W_Md8fHKRDaOZlxT_Kx3y7xBm4_kFQd98bcKuyzuPj6mKbSSxxe4uiHiYYtP0jQYUoxhI03d-2PK4LpdAedgcuqnZQ4Kx4U9WpPHk4m6OT4iilIf0hXP7y4LRl9A9N_w38_JiXwlDUI2AxMMI_XTJs4ycChw1xLo2LSKK_Bl-JQI_CA=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6zgzm1vw0i_SppBNnRLXAKuMlIc0tM-u42kdyKJYStFpuM10aitJa7Sa2uhXMo6l2xhhKeCFU6twEdzJf4ohHy9WNauzAPfEBibWGRG0783xR0lkaAgEuovhaJHnnrRNZl5Db7hMuNtb_d9NeASoj7YR3dF-SC75t8hU="
      },
      {
        "label": "reddit",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-15",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFdhT5Xcc-r-C8oLtJ8LJ2SLGP4GqscoZpIQbKJT95XX5jV8cPiTyi3oWEr98GuegJXCdmp8f_ZWPi8NujXGu82ABjX-LhSlGM9bIofIu-WshnGxDwzy80quYR0N-pF8H4iJQtyaPNnxWh8kdGOuKK-SsCS5f_fh82hmCRp-il-iw1nZXw8kjmo8DC-XQ4sNAKnl_PnXciCPw54cIkFEg=="
      },
      {
        "label": "reddit",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-15",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFdhT5Xcc-r-C8oLtJ8LJ2SLGP4GqscoZpIQbKJT95XX5jV8cPiTyi3oWEr98GuegJXCdmp8f_ZWPi8NujXGu82ABjX-LhSlGM9bIofIu-WshnGxDwzy80quYR0N-pF8H4iJQtyaPNnxWh8kdGOuKK-SsCS5f_fh82hmCRp-il-iw1nZXw8kjmo8DC-XQ4sNAKnl_PnXciCPw54cIkFEg=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6zgzm1vw0i_SppBNnRLXAKuMlIc0tM-u42kdyKJYStFpuM10aitJa7Sa2uhXMo6l2xhhKeCFU6twEdzJf4ohHy9WNauzAPfEBibWGRG0783xR0lkaAgEuovhaJHnnrRNZl5Db7hMuNtb_d9NeASoj7YR3dF-SC75t8hU="
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQElW1slL2jvZX2oSeFGMJedT-g11q6ycdGVt78fscNj3YyWw548Y_eNqbsr4W7Y4GlYUlzKhKaA2pjbxcLD9UKBLyzatjDzw4iv_l2_ZfhYdgI4gbXLe3saHuk6pyHWY3BR-13_FQRchoOP2zp33INOu_iiyi3d"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG5B0BHg4vci_8n5qAIBhJnAogtKVtiuTDCEAysf8MfrwXcthvmHItOdaKTMp1MCluv7-fSkZujKQRXTK5m5ZgQOal5yzFPxxYpcj2wzjyTCHc8X0RCHZjBh2GU2uDa8j3gDk0g2tbItzcQeeOkWWlY_kfMeIuN9B7wGPw="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPFttvLN7_axx5s9c8Hb2MNoS81D2KbzEox0RqaZ0_TWBzp4qsuv9voAAadpctGadGxa-Fmm9E_xSnbUc21iVEOwS0Ipv15AmjywcCJIxMLEcr8nItg3GOg1Xwa98wOYaHjsnOGxWO3-MF5XZBRiXQL8dqqpJ2O6FQjksASyw="
      },
      {
        "label": "lenovo",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEKXwcEGnkI8mXgLtiCj0Oozp-zW9-0lGMBgR6BB3cbTJrug_X8lMWvrpBWpVRChn2oyWpPki_z8vGtOzKAD46UtRr4T5iu8mtN97lqTGFSgpt_2LacNJEJaXN-PXEgnpOC3snvvUE0Q7-riXuwSnpYGjKwf62TXIyXzW5eBAhiHw3xBUO0Ns8="
      },
      {
        "label": "itglobal",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEGTCyGBkfyvN0Q2j_1bmB0amPIS50Wx5KcDBHQEjOuyP3J9BM_8EDnju33VRLIFKSG-JdARufaFYqOHbC6Rabb1SFJpvcLTMsmbXlkA5i0WojAK6oYNrMSJiXZ_5bNSYV7fmDJGllaekVvtfq3eaWfoj6oqN8wyNaoF3OYDiR-vDz4fuHaYzSkSbsnO0Sjrlkn6njgvOPnEgIno27OQA=="
      },
      {
        "label": "massedcompute",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHlUvy969KaCJ1uqk__lx1OJKstcqEMzP8Hur_q-LL7fV3VxC24pcxT9JqKzGGkE38hvqiSuT1WN_cypOJTrilkhPUStKW7sUskrbPY2jQWuySeWmYMnu_rlXu678Bml4FUoTs9E43YwAilsPxa8M-aRK52gDGZxlDyOFLZrATTlJBOXwXUAVurzf18tuxjKO-DCOwPl6Y7scHAzqI-x75VXmMLWozQaK_3T5MRywJDdMyk_gNL45VMP_gkiwvZhNo="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "computeprices",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEV-vazvrMlTzAWVHN_31n0GAl963lVpsy1d9DIoKq5V_qo9s7fBcoKWzP2OUeWK0Coh1bgu34aw7PRZcW-myM6h6xSoMvs8n4vrfqwg0qLkZ5GKwXXiqJuZHcH0Q7M"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-9",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEEGLYExcTUUadMLSiqrj2NvB9CmDb5eiyBUW6EC_nZARM3pdXELhDVudM4QRgisP7BAx-juWHqHhCBpV4b9N8CXVH5CbFww9Mz8C84j56TuTf7H3-rP3EbZ_ISp2VE5rKfHmXW53b6pvr_e1bKDzvyLMl66fZZhdTEzmmL_rThOqldTDty4FhReJ-8RPAghxpd2pu55zjsNOHrd9gGpz4eOdee3Y5B"
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQElW1slL2jvZX2oSeFGMJedT-g11q6ycdGVt78fscNj3YyWw548Y_eNqbsr4W7Y4GlYUlzKhKaA2pjbxcLD9UKBLyzatjDzw4iv_l2_ZfhYdgI4gbXLe3saHuk6pyHWY3BR-13_FQRchoOP2zp33INOu_iiyi3d"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "massedcompute",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHlUvy969KaCJ1uqk__lx1OJKstcqEMzP8Hur_q-LL7fV3VxC24pcxT9JqKzGGkE38hvqiSuT1WN_cypOJTrilkhPUStKW7sUskrbPY2jQWuySeWmYMnu_rlXu678Bml4FUoTs9E43YwAilsPxa8M-aRK52gDGZxlDyOFLZrATTlJBOXwXUAVurzf18tuxjKO-DCOwPl6Y7scHAzqI-x75VXmMLWozQaK_3T5MRywJDdMyk_gNL45VMP_gkiwvZhNo="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "computeprices",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEV-vazvrMlTzAWVHN_31n0GAl963lVpsy1d9DIoKq5V_qo9s7fBcoKWzP2OUeWK0Coh1bgu34aw7PRZcW-myM6h6xSoMvs8n4vrfqwg0qLkZ5GKwXXiqJuZHcH0Q7M"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "computeprices",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEV-vazvrMlTzAWVHN_31n0GAl963lVpsy1d9DIoKq5V_qo9s7fBcoKWzP2OUeWK0Coh1bgu34aw7PRZcW-myM6h6xSoMvs8n4vrfqwg0qLkZ5GKwXXiqJuZHcH0Q7M"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "amazon",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXEQfeO4_BQ3-HwiC3_kMllmxwBhX4kEg3vcFxWRIGVtjmXJBBJhebqKuon31kmA3ImUHEKCkTicmAT7hOdkxc9_jdvtP-4g32hX0PhKEg-jwaGmO0auNoX77cdtE91N2WIqU1Ct6qhO3va6glCHbyO16ICB_5SrldUdje7z186cMy6EMlJSecIhAdvbN1Ta-gPD2HgkSNj5KAeXHIaU7N7NPQHhx5cKr4HCOESRqGDBCC0z0H8T2QueI0pV8kCz9FzNM1KQ=="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "amazon",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXEQfeO4_BQ3-HwiC3_kMllmxwBhX4kEg3vcFxWRIGVtjmXJBBJhebqKuon31kmA3ImUHEKCkTicmAT7hOdkxc9_jdvtP-4g32hX0PhKEg-jwaGmO0auNoX77cdtE91N2WIqU1Ct6qhO3va6glCHbyO16ICB_5SrldUdje7z186cMy6EMlJSecIhAdvbN1Ta-gPD2HgkSNj5KAeXHIaU7N7NPQHhx5cKr4HCOESRqGDBCC0z0H8T2QueI0pV8kCz9FzNM1KQ=="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH8kVY07MCBPf1OFJrnWZLD5luLjJbjWAEWUMI8q2L9h5PxYNQ9qPWOmjJCCyb4y33c9yVznnCgfCQKHux0T0yKgKTJ8J-eF4zyRmRtvrJNpnzpSqXV9PquQO-BzkZyfyYzvREBtuEiVUsWfyr6kdyWG85e5e-KY_ycWmE-iVUSznUOcByBGQ=="
      },
      {
        "label": "massedcompute",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHlUvy969KaCJ1uqk__lx1OJKstcqEMzP8Hur_q-LL7fV3VxC24pcxT9JqKzGGkE38hvqiSuT1WN_cypOJTrilkhPUStKW7sUskrbPY2jQWuySeWmYMnu_rlXu678Bml4FUoTs9E43YwAilsPxa8M-aRK52gDGZxlDyOFLZrATTlJBOXwXUAVurzf18tuxjKO-DCOwPl6Y7scHAzqI-x75VXmMLWozQaK_3T5MRywJDdMyk_gNL45VMP_gkiwvZhNo="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH8kVY07MCBPf1OFJrnWZLD5luLjJbjWAEWUMI8q2L9h5PxYNQ9qPWOmjJCCyb4y33c9yVznnCgfCQKHux0T0yKgKTJ8J-eF4zyRmRtvrJNpnzpSqXV9PquQO-BzkZyfyYzvREBtuEiVUsWfyr6kdyWG85e5e-KY_ycWmE-iVUSznUOcByBGQ=="
      },
      {
        "label": "nvidia",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQElW1slL2jvZX2oSeFGMJedT-g11q6ycdGVt78fscNj3YyWw548Y_eNqbsr4W7Y4GlYUlzKhKaA2pjbxcLD9UKBLyzatjDzw4iv_l2_ZfhYdgI4gbXLe3saHuk6pyHWY3BR-13_FQRchoOP2zp33INOu_iiyi3d"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "theriseunion",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG5B0BHg4vci_8n5qAIBhJnAogtKVtiuTDCEAysf8MfrwXcthvmHItOdaKTMp1MCluv7-fSkZujKQRXTK5m5ZgQOal5yzFPxxYpcj2wzjyTCHc8X0RCHZjBh2GU2uDa8j3gDk0g2tbItzcQeeOkWWlY_kfMeIuN9B7wGPw="
      },
      {
        "label": "lenovo",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEKXwcEGnkI8mXgLtiCj0Oozp-zW9-0lGMBgR6BB3cbTJrug_X8lMWvrpBWpVRChn2oyWpPki_z8vGtOzKAD46UtRr4T5iu8mtN97lqTGFSgpt_2LacNJEJaXN-PXEgnpOC3snvvUE0Q7-riXuwSnpYGjKwf62TXIyXzW5eBAhiHw3xBUO0Ns8="
      },
      {
        "label": "itglobal",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEGTCyGBkfyvN0Q2j_1bmB0amPIS50Wx5KcDBHQEjOuyP3J9BM_8EDnju33VRLIFKSG-JdARufaFYqOHbC6Rabb1SFJpvcLTMsmbXlkA5i0WojAK6oYNrMSJiXZ_5bNSYV7fmDJGllaekVvtfq3eaWfoj6oqN8wyNaoF3OYDiR-vDz4fuHaYzSkSbsnO0Sjrlkn6njgvOPnEgIno27OQA=="
      },
      {
        "label": "runpod",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHf_Sae_qyGSorcwRt9ZQZQKaF5m3YEY4XyqcI2vZM9OpMHu8jEmEl6X9kFWAS_tWaEQubIf2vu165M--TooIPw_pkg5mIQuEp9FcagYXUrAqRI6d0SLLP6N8TDlujexws-VwijeboNrg3qC1RbV09q9j8-bL4l0T4IlTMKGzA="
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-12",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFsYhCoEewhbSoqA2_qUrJuHiRyLITgjK9tD7uZraef54dqB1rDZRxqO32k_WS7HgcKtnr3Il0sB7gU-D0Kgvl1ivOtaSJjeBMOBfZFG0fKh-ndeNPYK3_Sqi5vgHzYj3e_5Q6ERK1ypvzYqMI6Fcx_SzJsfRR4nS0EWdFubMJ83m-kGz8MWejJxFoaPf77JBb1j_KM9ycBraAOxkxU"
      },
      {
        "label": "dev",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHX9ImpdINqpM5wIsQ67-muehcQD4Q3V4C3xqtFZKDc0k_syXC1TY18eNE2fRSSCLuc8S1lIdxfqma0O9lxZroaD-DLLaXcBDmdipKAU8tybVKzX1KdT17MKA0n7EUjOk9gBSjtstyKWrTV4aiu4vuid0-4LbKfulGBj_dH8mnBBVl6NpVImebjfSwKBbLb"
      },
      {
        "label": "github",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-13",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFqD9H33hgEOxKflNwfZLcK54rd7xJpRgUUQMKjR-XDGztYgf_DauRjTDnvoJRlYaYBjjyqFkcRAE7R_bdSGG3msfoep7JV8o688in4i5g46VJPIL6mBJ0od98RxnHXVyxwZ1nx2w=="
      },
      {
        "label": "huggingface",
        "short_url": "https://vertexaisearch.cloud.google.com/id/2-14",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGoUi18LV4qVouYlLP40nrzeiqVE3zLZYRchphNal1Sx3aiFVD6CvxwzA_GYEp8AAPLEHQQ0ukEZ6Yee-aIbxz27hVWLZvMckhwNn1S-7b8wUgcsi1YsmOj6AmD01Bx03jEvoRcpJ9fFZo="
      }
    ],
    "initial_search_query_count": "3",
    "max_research_loops": "3",
    "research_loop_count": "2"
  }
}