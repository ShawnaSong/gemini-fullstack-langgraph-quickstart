{
  "file_name": "state_result_257.json",
  "conversion_timestamp": "2025-07-16T20:30:25.606912",
  "data": {
    "messages": [
      {
        "content": "What is some user feedback on using AMD EPYC to run LLM models",
        "additional_kwargs": {},
        "response_metadata": {},
        "type": "human",
        "name": null,
        "id": "2643116b-6164-4c95-86e9-2cfa02a524ed",
        "example": false
      },
      {
        "content": "User feedback on using AMD EPYC processors to run LLM models is generally positive, particularly for inference tasks and smaller AI deployments. Users have observed that EPYC systems are suitable for on-premise LLM inference, which prioritizes privacy and security [ahelpme](https://vertexaisearch.cloud.google.com/id/0-1]. The high core counts of AMD EPYC processors, especially the 9004 series (Genoa and Bergamo), often outperform Intel Xeon processors in multi-threaded workloads [1gbits](https://vertexaisearch.cloud.google.com/id/0-0). Memory bandwidth is a critical factor for LLM inference, and EPYC Genoa provides substantial bandwidth with its 12-channel DDR5 memory [ycombinator](https://vertexaisearch.cloud.google.com/id/0-2]. Some users have seen EPYC systems perform up to 6x faster than older Threadripper systems for larger models like LLaMa-2 70B [reddit](https://vertexaisearch.cloud.google.com/id/0-3]. For smaller organizations, a single server with a powerful AMD EPYC CPU (e.g., 9534) can be an entry point for running in-house AI chatbots, supporting a limited number of concurrent users [delltechnologies](https://vertexaisearch.cloud.google.com/id/0-8]. High-frequency AMD EPYC processors can also help balance latency and throughput in inference workloads [amd](https://vertexaisearch.cloud.google.com/id/0-5].\n\nHowever, it's important to note that while AMD EPYC CPUs are powerful, they are generally not considered optimal for LLM training compared to GPUs [massedcompute](https://vertexaisearch.cloud.google.com/id/0-6]. EPYC CPUs can play supporting roles in data preprocessing, inference for smaller models, and hybrid workloads [massedcompute](https://vertexaisearch.cloud.google.com/id/0-6].\n\nTo optimize LLM inference on AMD EPYC, users should consider software optimizations such as utilizing AI frameworks like TensorFlow, PyTorch, and ONNX Runtime [amd](https://vertexaisearch.cloud.google.com/id/1-2], employing the ZenDNN plugin [amd](https://vertexaisearch.cloud.google.com/id/1-2], using quantization [pugetsystems](https://vertexaisearch.cloud.google.com/id/1-4) [delltechnologies](https://vertexaisearch.cloud.google.com/id/1-5) [amd](https://vertexaisearch.cloud.google.com/id/1-6], and leveraging vLLM for efficient memory management [medium](https://vertexaisearch.cloud.google.com/id/1-8) [amd](https://vertexaisearch.cloud.google.com/id/1-9]. Hardware considerations include ensuring sufficient memory bandwidth [amd](https://vertexaisearch.cloud.google.com/id/1-2] and optimizing CPU-GPU communication [arxiv](https://vertexaisearch.cloud.google.com/id/1-12) [arxiv](https://vertexaisearch.cloud.google.com/id/1-13].\n\nUltimately, the choice between AMD EPYC and Intel Xeon depends on the specific workload, budget, and infrastructure requirements [1gbits](https://vertexaisearch.cloud.google.com/id/0-0], and software optimization plays a crucial role in maximizing performance on both platforms [vmware](https://vertexaisearch.cloud.google.com/id/0-13].",
        "additional_kwargs": {},
        "response_metadata": {},
        "type": "ai",
        "name": null,
        "id": "d0359f47-a9a2-4ee4-bca7-20f17a91324c",
        "example": false,
        "tool_calls": [],
        "invalid_tool_calls": [],
        "usage_metadata": null
      }
    ],
    "search_query": [
      "AMD EPYC user feedback running LLM models",
      "What specific software optimizations (e.g., compiler flags, libraries, or frameworks) are most effective for running LLM inference workloads on AMD EPYC processors, and how do they impact performance metrics like latency and throughput?"
    ],
    "web_research_result": [
      "Okay, I will conduct targeted Google Searches to gather the most recent, credible information on \"AMD EPYC user feedback running LLM models\" and synthesize it into a verifiable text artifact.\nBased on the search results, here's a synthesis of user feedback and performance data regarding AMD EPYC processors running LLM models:\n\n**General Performance and User Feedback:**\n\n*   AMD EPYC processors, particularly the 9004 series (Genoa and Bergamo), generally outperform Intel Xeon processors in multi-threaded workloads due to higher core counts [1gbits](https://vertexaisearch.cloud.google.com/id/0-0).\n*   Users find EPYC systems suitable for running LLM inference, especially in scenarios prioritizing privacy and security by running models on-premise [ahelpme](https://vertexaisearch.cloud.google.com/id/0-1).\n*   For LLM inference, memory bandwidth is a critical factor, and EPYC Genoa, with its 12-channel DDR5 memory, provides substantial bandwidth [ycombinator](https://vertexaisearch.cloud.google.com/id/0-2).\n*   Some users have observed that EPYC systems can be almost 6x faster than older Threadripper systems for larger models like LLaMa-2 70B [reddit](https://vertexaisearch.cloud.google.com/id/0-3).\n*   AMD EPYC processors can be a cost-effective solution for smaller AI deployments [amd](https://vertexaisearch.cloud.google.com/id/0-4).\n*   The AMD EPYC 9575F CPUs significantly improve latency-constrained inference serving, delivering enhanced performance compared to Intel Xeon CPUs [amd](https://vertexaisearch.cloud.google.com/id/0-5).\n\n**Training LLMs:**\n\n*   While AMD EPYC CPUs are powerful, they are generally not considered optimal for LLM training compared to GPUs [massedcompute](https://vertexaisearch.cloud.google.com/id/0-6). GPUs excel due to their parallel processing capabilities, high memory bandwidth, and specialized hardware like Tensor Cores [massedcompute](https://vertexaisearch.cloud.google.com/id/0-6).\n*   However, EPYC CPUs can play supporting roles in data preprocessing, inference for smaller models, and hybrid workloads [massedcompute](https://vertexaisearch.cloud.google.com/id/0-6).\n*   AMD is actively working on optimizing LLM fine-tuning with its Instinct GPUs, achieving competitive training times on platforms like MI325X and MI300X [amd](https://vertexaisearch.cloud.google.com/id/0-7).\n*   AMD's MLPerf training submission on MI325X and MI300X platforms based on the Llama 2 70B LoRA Finetuning workload performance shows leadership in ML performance [amd](https://vertexaisearch.cloud.google.com/id/0-7).\n\n**Inference Specifics:**\n\n*   For smaller organizations, a single server with a powerful AMD EPYC CPU (e.g., 9534) can be an entry point for running in-house AI chatbots, supporting a limited number of concurrent users [delltechnologies](https://vertexaisearch.cloud.google.com/id/0-8).\n*   Lanner's NCA-6130 Edge AI server, featuring an AMD EPYC 9005 processor and Instinct MI210 GPU, demonstrates boosted response times for LLaMA LLM workloads in private network environments [youtube](https://vertexaisearch.cloud.google.com/id/0-9).\n*   High-frequency AMD EPYC processors can help balance latency and throughput in inference workloads [amd](https://vertexaisearch.cloud.google.com/id/0-5).\n*   CPU performance can be a bottleneck for low-batch latency in LLM inference, even in CPU-GPU coupled systems [arxiv](https://vertexaisearch.cloud.google.com/id/0-10).\n\n**AMD EPYC vs. Intel Xeon:**\n\n*   AMD EPYC processors often demonstrate better performance per watt compared to Intel Xeon, potentially leading to lower data center power consumption [1gbits](https://vertexaisearch.cloud.google.com/id/0-0).\n*   In some benchmarks (Cinebench R23, SPEC CPU 2017), AMD EPYC outperforms Intel Xeon in raw multi-threaded workloads [1gbits](https://vertexaisearch.cloud.google.com/id/0-0).\n*   For virtualization workloads, EPYC can offer superior consolidation ratios [1gbits](https://vertexaisearch.cloud.google.com/id/0-0).\n*   Intel Xeon may retain advantages in specific areas like mature Trusted Execution Technology (TXT) and legacy software ecosystem support [1gbits](https://vertexaisearch.cloud.google.com/id/0-0).\n*   Intel is actively working to improve the AI performance of its Xeon processors, with claims of competitive performance against AMD EPYC in certain scenarios [semiwiki](https://vertexaisearch.cloud.google.com/id/0-11).\n*   Intel Xeon 6980P delivers higher performance and performance/watt compared to AMD EPYC 9755 on several workloads like Recommendation System DLRM, Stable Diffusion, and Language Processing BERT-large [intel](https://vertexaisearch.cloud.google.com/id/0-12).\n\n**Specific Models and Configurations:**\n\n*   AMD EPYC processors are used with various LLMs, including Llama 2, Llama 3, and StarChat2 [vmware](https://vertexaisearch.cloud.google.com/id/0-13) [amd](https://vertexaisearch.cloud.google.com/id/0-14) [amd](https://vertexaisearch.cloud.google.com/id/0-4).\n*   For code generation tasks, smaller LLMs like StarChat2 15B can be effectively run on CPU-based architectures with AMD EPYC processors [vmware](https://vertexaisearch.cloud.google.com/id/0-13).\n*   The 2P AMD EPYC 9654 system achieved a ~1.21x inference uplift versus the 2P Intel Xeon Platinum 8592+ system [amd](https://vertexaisearch.cloud.google.com/id/0-14).\n*   DeepSeek R1 Distill Llama 8B can achieve fast speeds (50 tokens per second) on an AMD EPYC 9954 system, suitable for daily routines [ahelpme](https://vertexaisearch.cloud.google.com/id/0-1).\n\n**Keep in Mind:**\n\n*   Some performance comparisons are based on internal testing by AMD or Intel, so consider independent benchmarks for a balanced view [semiwiki](https://vertexaisearch.cloud.google.com/id/0-11) [amd](https://vertexaisearch.cloud.google.com/id/0-5) [amd](https://vertexaisearch.cloud.google.com/id/0-4).\n*   The choice between AMD EPYC and Intel Xeon depends on the specific workload, budget, and infrastructure requirements [1gbits](https://vertexaisearch.cloud.google.com/id/0-0).\n*   Software optimization plays a crucial role in maximizing performance on both AMD and Intel platforms [vmware](https://vertexaisearch.cloud.google.com/id/0-13).\n",
      "It appears that optimizing LLM inference workloads on AMD EPYC processors involves a multifaceted approach, considering software optimizations, hardware configurations, and the interplay between CPUs and GPUs [amd](https://vertexaisearch.cloud.google.com/id/1-0) [amd](https://vertexaisearch.cloud.google.com/id/1-1). Here's a synthesis of effective strategies and their impact:\n\n**1. Software Optimizations and Frameworks:**\n\n*   **Framework Support:** Utilize AI frameworks like TensorFlow, PyTorch, and ONNX Runtime, as AMD integrates optimizations into these frameworks [amd](https://vertexaisearch.cloud.google.com/id/1-2).\n*   **ZenDNN Plugin:** Employ the ZenDNN plugin to optimize operators, leverage microkernels, and implement efficient multithreading on AMD EPYC cores, accelerating AI inference workloads [amd](https://vertexaisearch.cloud.google.com/id/1-2).\n*   **ML Compilation (MLC):** Consider MLC techniques via the TVM Unity software stack for cross-hardware performance optimizations [ycombinator](https://vertexaisearch.cloud.google.com/id/1-3).\n*   **Quantization:** Use quantization to reduce memory bandwidth requirements. Options include INT8, FP8, and sub-4-bit dynamic quantizations [pugetsystems](https://vertexaisearch.cloud.google.com/id/1-4) [delltechnologies](https://vertexaisearch.cloud.google.com/id/1-5). AMD also provides the AMD Quark model optimization library, which focuses on AI model quantization [amd](https://vertexaisearch.cloud.google.com/id/1-6).\n*   **Compiler Flags:** Use the `-xHost` compiler flag to select the best optimization options for the processor [intel](https://vertexaisearch.cloud.google.com/id/1-7).\n*   **vLLM:** Utilize vLLM for efficient memory management (PagedAttention), continuous batching, speculative decoding, and parallel sampling [medium](https://vertexaisearch.cloud.google.com/id/1-8). The AMD AITER framework can be integrated with vLLM for further performance gains [amd](https://vertexaisearch.cloud.google.com/id/1-9).\n*   **KServe:** Deploy models on Kubernetes using KServe with the AMD Inference Server for an easy-to-use inference solution designed for AMD CPUs [github](https://vertexaisearch.cloud.google.com/id/1-10).\n*   **ROCm:** Utilize the ROCm open software stack to run AI tools on multiple Radeon PRO GPUs [amd](https://vertexaisearch.cloud.google.com/id/1-11).\n\n**2. Hardware Considerations and CPU-GPU Collaboration:**\n\n*   **CPU Core Count and Frequency:** Higher core counts (up to 192 \"Zen 5\" cores) and higher frequencies (up to 5 GHz) in AMD EPYC processors can improve parallelism and reduce the need for GPU acceleration [amd](https://vertexaisearch.cloud.google.com/id/1-2) [amd](https://vertexaisearch.cloud.google.com/id/1-1).\n*   **Memory Bandwidth:** Ensure sufficient memory bandwidth (DDR5 memory) for fast data processing [amd](https://vertexaisearch.cloud.google.com/id/1-2).\n*   **CPU-GPU Coupling:**  Optimize CPU-GPU communication, especially in loosely-coupled systems [arxiv](https://vertexaisearch.cloud.google.com/id/1-12) [arxiv](https://vertexaisearch.cloud.google.com/id/1-13). Consider technologies like NVLink for faster interconnects [medium](https://vertexaisearch.cloud.google.com/id/1-8) [ycombinator](https://vertexaisearch.cloud.google.com/id/1-3).\n*   **Hybrid Inference:** Explore hybrid CPU/GPU inference, which offers a more affordable alternative to pure GPU inference, balancing cost and performance [pugetsystems](https://vertexaisearch.cloud.google.com/id/1-4).\n*   **NUMA Configuration:** Optimize NUMA (Non-Uniform Memory Access) settings for LLM inference by disabling NUMA balancing and enabling memory interleaving to reduce thread and memory page migrations [arxiv](https://vertexaisearch.cloud.google.com/id/1-14).\n\n**3. Impact on Performance Metrics:**\n\n*   **Latency:** High-frequency AMD EPYC CPUs (e.g., 9575F) can significantly improve latency-constrained inference serving [amd](https://vertexaisearch.cloud.google.com/id/1-1). Balancing latency and throughput is crucial for real-time applications [amd](https://vertexaisearch.cloud.google.com/id/1-1).\n*   **Throughput:** Optimizations like AITER integration and specific configurations in vLLM can deliver higher throughput [amd](https://vertexaisearch.cloud.google.com/id/1-9).  Increasing batch sizes can also improve throughput, but this often increases latency [amd](https://vertexaisearch.cloud.google.com/id/1-1).\n*   **Tokens per Second:** Benchmarks using llama.cpp show that optimized configurations on AMD EPYC processors can achieve impressive tokens per second generation rates [ahelpme](https://vertexaisearch.cloud.google.com/id/1-15) [ahelpme](https://vertexaisearch.cloud.google.com/id/1-16).\n*   **Scalability:** Tensor parallelism can be used to scale LLM inference across multiple CPUs, potentially achieving similar performance to a single powerful CPU [reddit](https://vertexaisearch.cloud.google.com/id/1-17).\n\n**4. Model-Specific Considerations:**\n\n*   **Model Size and Quantization:**  The size of the LLM significantly impacts performance. Quantization can help reduce the model size and memory footprint, allowing for deployment on a wider range of hardware [ahelpme](https://vertexaisearch.cloud.google.com/id/1-15) [pugetsystems](https://vertexaisearch.cloud.google.com/id/1-4) [ahelpme](https://vertexaisearch.cloud.google.com/id/1-16).\n*   **Mixed Precision Training:** Models trained with mixed precision frameworks (e.g., FP8) can offer performance benefits [pugetsystems](https://vertexaisearch.cloud.google.com/id/1-4).\n\n**5. Key Takeaways:**\n\n*   AMD EPYC processors are well-suited for small to medium AI models and workloads where proximity to data matters [amd](https://vertexaisearch.cloud.google.com/id/1-2).\n*   A sufficiently optimized software stack is crucial for cost-efficient LLM serving on AMD GPUs [ycombinator](https://vertexaisearch.cloud.google.com/id/1-3).\n*   The choice of host CPU can significantly impact GPU investments, especially with stricter performance requirements for serving LLMs [amd](https://vertexaisearch.cloud.google.com/id/1-1).\n*   Memory bandwidth is a critical factor during the decoding phase of LLM inference [pugetsystems](https://vertexaisearch.cloud.google.com/id/1-4) [andrewkchan](https://vertexaisearch.cloud.google.com/id/1-18).\n\nIt's important to note that the effectiveness of specific optimizations can depend on the specific LLM, the hardware configuration, and the workload characteristics. Continuous benchmarking and profiling are essential to identify the optimal settings for a given scenario [amd](https://vertexaisearch.cloud.google.com/id/1-0) [arxiv](https://vertexaisearch.cloud.google.com/id/1-12).\n"
    ],
    "sources_gathered": [
      {
        "label": "1gbits",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnnJeJZt3Qd5J79D3c_iNjbRNu3WzfDXP2jjSnOY3Lalh9pnHofw5nvVCOLxmSq8rhZZcRHKTbt_MkcYAOwE1My94EBeZyGf_2p1Q9rCk0JP-BqJjgHxEVLCUeIUX4J4GyjEO01NQn7wDD"
      },
      {
        "label": "ahelpme",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEcAjag2sBCekLeCFLTtxQ_LOWTBwNfU_rkxL-l1W95K8lJUs3rpBeWsfyUwavSh8pQsbd_fI6LjYYxhcWT467q4FKgqQYx35hA4A9Y0OL4CdS6YyLDp1GwmUstMix5UxMsjv1IJHAdouacOcXNW6BfDWS2HDEW7VoBnW1znd1KTS3o_tM9_c_MEIlIaKURTwU="
      },
      {
        "label": "ycombinator",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF8qc6SiXz6qfs95jBQlNT7swijQotUjvGwV18xfAYdtnOXt4SiDyBAuSdQEqPY3J61_NCiznkdurNz5xcQ2k7zDmjgMjRlEW8_5gloXLar5NjUy2ZLY4ap4H-mrdnAVyeYMeRs92deyQ=="
      },
      {
        "label": "reddit",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzYKGy6fe6cHzOiMTha44Y9LleOOszy2fAFEzyNjqLwJE2mmVQQ3M-4cF2nMRGB8_w6D6k6Zd5fecbw3aTxtCY-iNlWv8JwgpWZPe2SUfGAQQR1AjkMUlYqlUncFOeOKyOhLELHwOWcptz5PewTm1QJQer_-gy7xgMCOlIpKE80LfGFYMbNcgRbd9i2th1_MGbBcemj8wtPZQ3QtI="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEU7Rb2Cp4KD4wv4FW1JthFGqWA-fa6trq062R0zr0IW2CyITG2ygZA5tc77EhNkisQzIXco_4m-7YXJCU8MQGSgDH-Kry1Es5dp9VIWLLSjkNsE0HiRzvy2FCXvEdcgTxHGUnbgxPSQl8sxNRRGi45TpjK6xfUHIPIwKbLKXM-vvVfcL55akwxVk5gudFEC1KJblLo9TLfbktVlWI5eQlO2ID4EK0_2ZKbFeVnZ8hS3J6uLFK3Mribv141kZ0="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHF94abIBe5GctyQEz8d-1rApo_-VzhtA9b2GNJjgPy2xT1jQTvdbb1BllpsHyUCGtbqhVx-jxwx3Vtynd492B1iHkATqHvZUJczZ3Mkb-eEdwPn3jKit5tY1pPlBYbhLDWBjhSRxfdrSO2gjijeINkmarSQ_mWIZexBDY55VsJQHzj6IFsmf4P5UvFSn4sGihuqK1OdSFMY6Z80w=="
      },
      {
        "label": "massedcompute",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHBptqDGH3uSmprZ41ZIolLu1uYc3vJCNvqasVDmDTKq7TcYArURCRB-WoFz7TqyRI1XZeKcEPzStJ3bknSjeQkaJ5LUoTxnOUIfWrEjrpK8UH3ihCsyEuvl_R5__yZSLzR3pjrnmDZk5IJ9lLyd8n_SznQvi6VzGvNXj0zdq9fUjT0tayHml5ehfPLvdOsgF_b2ml5a5ai3udbtBm5ow3Uje31EYMRUyEYtr80ZqOOPS0XpRqaR0VgUWbc9g=="
      },
      {
        "label": "massedcompute",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHBptqDGH3uSmprZ41ZIolLu1uYc3vJCNvqasVDmDTKq7TcYArURCRB-WoFz7TqyRI1XZeKcEPzStJ3bknSjeQkaJ5LUoTxnOUIfWrEjrpK8UH3ihCsyEuvl_R5__yZSLzR3pjrnmDZk5IJ9lLyd8n_SznQvi6VzGvNXj0zdq9fUjT0tayHml5ehfPLvdOsgF_b2ml5a5ai3udbtBm5ow3Uje31EYMRUyEYtr80ZqOOPS0XpRqaR0VgUWbc9g=="
      },
      {
        "label": "massedcompute",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHBptqDGH3uSmprZ41ZIolLu1uYc3vJCNvqasVDmDTKq7TcYArURCRB-WoFz7TqyRI1XZeKcEPzStJ3bknSjeQkaJ5LUoTxnOUIfWrEjrpK8UH3ihCsyEuvl_R5__yZSLzR3pjrnmDZk5IJ9lLyd8n_SznQvi6VzGvNXj0zdq9fUjT0tayHml5ehfPLvdOsgF_b2ml5a5ai3udbtBm5ow3Uje31EYMRUyEYtr80ZqOOPS0XpRqaR0VgUWbc9g=="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEB1dydHvoZ6jc5a2WSZV4rjyx7_MaZq-EXt6NR7wNYIeW0j2p_MAc56ks2o7D-dPSJhfYByLpkSRPbz-kA_jhPD3cqDiTt_Ya15dgk0RPzwwd0vXlmoFq-WbJYGSLCt5GR940pnZpQ72H6ZviEV22md8jEwlETa1gI3NbzjRMtlUcQ_cjKE49Hn0qSCWS_"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEB1dydHvoZ6jc5a2WSZV4rjyx7_MaZq-EXt6NR7wNYIeW0j2p_MAc56ks2o7D-dPSJhfYByLpkSRPbz-kA_jhPD3cqDiTt_Ya15dgk0RPzwwd0vXlmoFq-WbJYGSLCt5GR940pnZpQ72H6ZviEV22md8jEwlETa1gI3NbzjRMtlUcQ_cjKE49Hn0qSCWS_"
      },
      {
        "label": "delltechnologies",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGqF-qzoFcnIramguDhbmCNRaYcMSXRiF5SZtNVoHoc_pNWUDct7O1h-cfvkxuup-I1t8CNdnr60W9IHMBaC6AbkgtfuiVCt3emIwdmoNSfXExQV3UxLg7X9nIw_mrx2uhjGbf5TzMMDqk0PDkSUav06Bcn5dVOPrzOvNd0hcSX01AtMVE3Ssk9gU1s2zyKmyQpbdXnKBwwk5fPlr7fTevC2O2YcfZ-4oxu9VlHxu-SOcE1Ktqk-PmDolaSHo0Y0bjTHCT3kzr5Jg=="
      },
      {
        "label": "youtube",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-9",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGbRvBQaM261VtI8enEVMhLtiaa7XzWZFm2AO_6GMiD0Dpqxz4MdqhVG10WF8IhN2aLQwFGpUVNE5AqN-5jbi2U_b_HAQe3LaD_X4RYdxTuIRehuWnGkR2RQtCNgro3uPU7syI4YNQ="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHF94abIBe5GctyQEz8d-1rApo_-VzhtA9b2GNJjgPy2xT1jQTvdbb1BllpsHyUCGtbqhVx-jxwx3Vtynd492B1iHkATqHvZUJczZ3Mkb-eEdwPn3jKit5tY1pPlBYbhLDWBjhSRxfdrSO2gjijeINkmarSQ_mWIZexBDY55VsJQHzj6IFsmf4P5UvFSn4sGihuqK1OdSFMY6Z80w=="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFAhp9WvUXn9qUomytjcz1aKEo1TE6QuJ_xzo8oRnLXzM_sB7Ky6BVY8Poad7p5PhADE1AwKPv8yNaG_VYYYrbIbyh3VVs2afHwcAG2Uep-lpUTpZpkE0p8-Yl3"
      },
      {
        "label": "1gbits",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnnJeJZt3Qd5J79D3c_iNjbRNu3WzfDXP2jjSnOY3Lalh9pnHofw5nvVCOLxmSq8rhZZcRHKTbt_MkcYAOwE1My94EBeZyGf_2p1Q9rCk0JP-BqJjgHxEVLCUeIUX4J4GyjEO01NQn7wDD"
      },
      {
        "label": "1gbits",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnnJeJZt3Qd5J79D3c_iNjbRNu3WzfDXP2jjSnOY3Lalh9pnHofw5nvVCOLxmSq8rhZZcRHKTbt_MkcYAOwE1My94EBeZyGf_2p1Q9rCk0JP-BqJjgHxEVLCUeIUX4J4GyjEO01NQn7wDD"
      },
      {
        "label": "1gbits",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnnJeJZt3Qd5J79D3c_iNjbRNu3WzfDXP2jjSnOY3Lalh9pnHofw5nvVCOLxmSq8rhZZcRHKTbt_MkcYAOwE1My94EBeZyGf_2p1Q9rCk0JP-BqJjgHxEVLCUeIUX4J4GyjEO01NQn7wDD"
      },
      {
        "label": "1gbits",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnnJeJZt3Qd5J79D3c_iNjbRNu3WzfDXP2jjSnOY3Lalh9pnHofw5nvVCOLxmSq8rhZZcRHKTbt_MkcYAOwE1My94EBeZyGf_2p1Q9rCk0JP-BqJjgHxEVLCUeIUX4J4GyjEO01NQn7wDD"
      },
      {
        "label": "semiwiki",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH_NpP2U3I4o6Y3oZOJxuOOKdeSMYWoNNIfQG_OCx43G-t1wL1De8sNS6GZoz5OvzEK3ZEBJA9DSvgnlGEu96w60z6pgXhxGd1hK1Mv3-9j0P2nOacCxYbjrfWuRrBD2ChkhTb7YSECSPorMXjJJkSE1fFsc9QTJlZS9dWd8tLAjV6akQQCCuA0w_DVc42pdQkDPQkWjnWhUYpxo5Sq"
      },
      {
        "label": "intel",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-12",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEF5Gk3LEk9WqweIwtufJuVGLGUEmWE8BOdAICZivlhW-hDYMo_mxkSa-lv7dKP0ZOR7PzZy1tWTYyG-w8HXNO21AXnru9hs8ZG-rMyeiVLFTR3UU99B3ZNbsZgp6WZBrTfzRKNThvadVglhum4QzJdmqZj-dbI5m5l-rqEVGhbhWgsQxezO64zrlc-9UQwGxc="
      },
      {
        "label": "vmware",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-13",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHFMw3cfsub0KS0SUu5Fp2srzQK1m6N6dlqswYp0qzUyN7xsYo35qR45iIlsJW5rpBGwKHk0jIxcV4NjszzQbqwvBKRb0ADLeK80_ofTYoZJoCOxuZnKo9oORyxkj9Ojw67Kfsb1BtBIz1Ygxlig2u1DH5IYWddjZx1YKqAYTVBhs6Aljo9fJpEntJVnJI6i_Mijc9gG47ImK651RtpbIJjfH3n3pqYPYI06eg87O42toDAZm7hGw=="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-14",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHUaqyxtlZA7r9XuxSFLl_FMgtjgSZPubW5FBwVJCVu35YvMyZwcBG-2-gIttSRNu4ywJBelalnrM8HMKVt7iRVHFB51yAqvFjYlyoh-TXCzysjWYtK9tJxyQI77SSCW70EqFqGnfk22MHMsq5ZjlRnz5YLPpb9N7hdKzzlw0UYBdOn-6KTSe75yaIaRJSQeWuhev4="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEU7Rb2Cp4KD4wv4FW1JthFGqWA-fa6trq062R0zr0IW2CyITG2ygZA5tc77EhNkisQzIXco_4m-7YXJCU8MQGSgDH-Kry1Es5dp9VIWLLSjkNsE0HiRzvy2FCXvEdcgTxHGUnbgxPSQl8sxNRRGi45TpjK6xfUHIPIwKbLKXM-vvVfcL55akwxVk5gudFEC1KJblLo9TLfbktVlWI5eQlO2ID4EK0_2ZKbFeVnZ8hS3J6uLFK3Mribv141kZ0="
      },
      {
        "label": "vmware",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-13",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHFMw3cfsub0KS0SUu5Fp2srzQK1m6N6dlqswYp0qzUyN7xsYo35qR45iIlsJW5rpBGwKHk0jIxcV4NjszzQbqwvBKRb0ADLeK80_ofTYoZJoCOxuZnKo9oORyxkj9Ojw67Kfsb1BtBIz1Ygxlig2u1DH5IYWddjZx1YKqAYTVBhs6Aljo9fJpEntJVnJI6i_Mijc9gG47ImK651RtpbIJjfH3n3pqYPYI06eg87O42toDAZm7hGw=="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-14",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHUaqyxtlZA7r9XuxSFLl_FMgtjgSZPubW5FBwVJCVu35YvMyZwcBG-2-gIttSRNu4ywJBelalnrM8HMKVt7iRVHFB51yAqvFjYlyoh-TXCzysjWYtK9tJxyQI77SSCW70EqFqGnfk22MHMsq5ZjlRnz5YLPpb9N7hdKzzlw0UYBdOn-6KTSe75yaIaRJSQeWuhev4="
      },
      {
        "label": "ahelpme",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEcAjag2sBCekLeCFLTtxQ_LOWTBwNfU_rkxL-l1W95K8lJUs3rpBeWsfyUwavSh8pQsbd_fI6LjYYxhcWT467q4FKgqQYx35hA4A9Y0OL4CdS6YyLDp1GwmUstMix5UxMsjv1IJHAdouacOcXNW6BfDWS2HDEW7VoBnW1znd1KTS3o_tM9_c_MEIlIaKURTwU="
      },
      {
        "label": "semiwiki",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH_NpP2U3I4o6Y3oZOJxuOOKdeSMYWoNNIfQG_OCx43G-t1wL1De8sNS6GZoz5OvzEK3ZEBJA9DSvgnlGEu96w60z6pgXhxGd1hK1Mv3-9j0P2nOacCxYbjrfWuRrBD2ChkhTb7YSECSPorMXjJJkSE1fFsc9QTJlZS9dWd8tLAjV6akQQCCuA0w_DVc42pdQkDPQkWjnWhUYpxo5Sq"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHF94abIBe5GctyQEz8d-1rApo_-VzhtA9b2GNJjgPy2xT1jQTvdbb1BllpsHyUCGtbqhVx-jxwx3Vtynd492B1iHkATqHvZUJczZ3Mkb-eEdwPn3jKit5tY1pPlBYbhLDWBjhSRxfdrSO2gjijeINkmarSQ_mWIZexBDY55VsJQHzj6IFsmf4P5UvFSn4sGihuqK1OdSFMY6Z80w=="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEU7Rb2Cp4KD4wv4FW1JthFGqWA-fa6trq062R0zr0IW2CyITG2ygZA5tc77EhNkisQzIXco_4m-7YXJCU8MQGSgDH-Kry1Es5dp9VIWLLSjkNsE0HiRzvy2FCXvEdcgTxHGUnbgxPSQl8sxNRRGi45TpjK6xfUHIPIwKbLKXM-vvVfcL55akwxVk5gudFEC1KJblLo9TLfbktVlWI5eQlO2ID4EK0_2ZKbFeVnZ8hS3J6uLFK3Mribv141kZ0="
      },
      {
        "label": "1gbits",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnnJeJZt3Qd5J79D3c_iNjbRNu3WzfDXP2jjSnOY3Lalh9pnHofw5nvVCOLxmSq8rhZZcRHKTbt_MkcYAOwE1My94EBeZyGf_2p1Q9rCk0JP-BqJjgHxEVLCUeIUX4J4GyjEO01NQn7wDD"
      },
      {
        "label": "vmware",
        "short_url": "https://vertexaisearch.cloud.google.com/id/0-13",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHFMw3cfsub0KS0SUu5Fp2srzQK1m6N6dlqswYp0qzUyN7xsYo35qR45iIlsJW5rpBGwKHk0jIxcV4NjszzQbqwvBKRb0ADLeK80_ofTYoZJoCOxuZnKo9oORyxkj9Ojw67Kfsb1BtBIz1Ygxlig2u1DH5IYWddjZx1YKqAYTVBhs6Aljo9fJpEntJVnJI6i_Mijc9gG47ImK651RtpbIJjfH3n3pqYPYI06eg87O42toDAZm7hGw=="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEEyj0Z0P_4VQ9LAyUP29ptg1o62MjVnAPNl3inogoHXGhspsd2qRO2sB_1PJJwVaBiNTHJd9Nxmu3NCZIj7Uyzv8oMjB4lswh99wgAfzjlWjLbfQaYY0ACtRbHfrWUJv8dXPdFKhKqL1Sifcr4n4F9FyQieBshlp8UqdU_TqntXlXmIyr9gQe0m-WINj2IW72epjgfFdb520IWKFjv7RhUCbk7PEVr3oMjbYoRWq6du9WqJVKzaNT1eZLN9buK8I4-L2U="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvlVtZ-TfFHfX0-Q1l9gYwEXqxCWqi1p1-3aNbj-tlTyrnclDMENYAxlm_qIoUbz4wMtjUblvImSjuqpaf91Y6iOrAFKnNslkSWQR9NuPceioKuQurUFsQVgbyorbFlzzklFiK7R75YX4iowQAvW5Vwm-ikv-D73CjR4C4VcS3iDaNiaQAqarT53Ff1ikragBJOAdYHhlDa1S4"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG71RBm7Ox2Lm_FZTtjZP6i_R8TzDUOi-GS6U75ZPc71dICyojw7KRDCyt5Iejb1kUea0cUYqmLvZKHYLiod8Dv1qd0s5WYnkGIXwvfvnLcOxagJe-gXx4zd2mWvLThxJFqvuJPc-C61xTS0yN1dSEvzcni23a_8I6cPI8iQ58qBAli3zaIz7o="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG71RBm7Ox2Lm_FZTtjZP6i_R8TzDUOi-GS6U75ZPc71dICyojw7KRDCyt5Iejb1kUea0cUYqmLvZKHYLiod8Dv1qd0s5WYnkGIXwvfvnLcOxagJe-gXx4zd2mWvLThxJFqvuJPc-C61xTS0yN1dSEvzcni23a_8I6cPI8iQ58qBAli3zaIz7o="
      },
      {
        "label": "ycombinator",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJu6EXr2tXNvB-q6XH5-YvnVKNmt90NarymKYytwTkBPo4knNnMLEtJCTIyld4ARlAC7NV2uhxPCLO5nyndIelg-g3Ft729_Acg6GWKVPwUfREHUmlKWrU0EgE9TdELE45WjKh5Fl1"
      },
      {
        "label": "pugetsystems",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZtZ1rRX8FPNlxaCrKPJu5oYcWL1gGir4MBYdj_BQZTvvFun4lKadvOXkrSCSNaTnpfKJJQLf0ZbyISYtFkXrg1rY-WlNR2YmfbSgfoKyPP90wfMSMuFT40Pb1rt3GvKSpP3lNthYoRRnxns8SiEAeWm6ZuNXsvcBeKuQsMgHiae-XN4LwPH0="
      },
      {
        "label": "delltechnologies",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-5",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFwJKiAUFZF2HfqmeUjjRv1D9v65EwSdTsT6S8IIqXqolav2rB9b4dRMUcxxXbHuGTOUBswpNPdNMAubllItw_g3h4F1SfPETrZS86xpjvQP2-aR8i27CWBhQ0zf0fpek4vM8oRHvm1qBJk8ZgCJ9BdSq46rmR7L42hPqyfqQuoUjFJfyJvpzSqA_jcTCVSsSWD0hhigRu7ScefWiCOhaBsoAS2kGFH4iRBP6TP1yaSsQLBnEw1gHmzp1h0eDTtG94="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-6",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHRD22P4YnUloSyzr_xt7ybvpeunY7d7O-8foCmACNKGQfSIkyR2Bd7FTNfZYPbQ3MYVY9jFW27EYq69tXrnoKl1eJrMH2kIIiJ164gOyoA9bya8-sdNXKKFfSPxgLlgndIIIjuvzFjztSdO63EknNdiL_FJuySAEhjsGUp5Ut_zyAID08Ax3WtJj9iomVrdb7NNXY64T-H2f4t7hnToRgV2f9CRHkYao1Htn8hd9rakgb1Vw3aTGlmoDALs8dEmRQ8m48="
      },
      {
        "label": "intel",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-7",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFz6qli7r3HjYJ5SBY9e6AqgnoVBPbD7VF8xMbPm0rwa4AnaJAkEnXs4VOPSJUzk0ZpK9bBUZT02RnivcLrhrUrp5e174VnMI_4y-wNtdqoZXOCTmiJ9mW0ghMLmVeYJ5n0HCxBEVa3N-ZiHpaReCAc-tJkIUy3Z0in6LJ75ZE_hCzTBTvfuXqiLmVBcJVTCvWp8Oi7a8S61FfeVEZKuErtpZQC"
      },
      {
        "label": "medium",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHyRS5fMEJjhpu8b4l70Vrl8Igca3mIpiF-yRpW56hFOG1Wlgtpvj7zK-CHQn7f0FPsHkhfLt7MD1gW95QMZjqBTlgLtN7wL3KjYN3rTkE9oFZNUkSowTUbzxtT3C_9xIiGVLROC9A7Q6VvIrICUkcZQldbHeYhNb9dQmFF5Q3smBfad0L68u08Fbe3S_Lmxqq0C_dY5s2tcKgNTOcKby60fvHHaZfl"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-9",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEYOvbTnUOceuSkL8OIVJ7t29daogwo3fg_vn5NGFpp62Wcan-pniEJZAKwfo4IKlqITkCixIHyPAcCkp8KrTgP8OCGTxtFUFP3Nj60BBiPOLZVCUIQioEkCyRDCtY3wtLg1R5dqjQb3h8NPORrwN013xUs8Oknu9T-jh1ywM-mI5yMumSLM9ZdRowUCQ=="
      },
      {
        "label": "github",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-10",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGIrcO-aQP7T4D-przEpnI0_XSbMu0UixQHry5iY8E-zcOfIWY0aUf5qbuPnIY7p4RhB76upWX-rxoTbHNm_a6Z2oWV452XN-1OsC5hmRrEwlEjOB2SmL0v-8v-LjJHcaZXYgY8Xz-YvF6YmO6yDS3N3OrqOckkBAGLBHA="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-11",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF6lNyFlqhvrEH68LFYmYNYu4MAzvjoPOj8sLKajRpuL3L1JkMNCi1qz3IZ5CY24x_Q_tmHv9LqLf-iuorkGSS6-MwRN7uLvmv6b1faD9ta-UNt3xXpPVlbywuC1_HBq8hKS3FwcUohb-SYXj1i0M4La-d_TM_OLrZSYKsj2GS_eD0rZbyk5MMb0aZYS65lktj9"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG71RBm7Ox2Lm_FZTtjZP6i_R8TzDUOi-GS6U75ZPc71dICyojw7KRDCyt5Iejb1kUea0cUYqmLvZKHYLiod8Dv1qd0s5WYnkGIXwvfvnLcOxagJe-gXx4zd2mWvLThxJFqvuJPc-C61xTS0yN1dSEvzcni23a_8I6cPI8iQ58qBAli3zaIz7o="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvlVtZ-TfFHfX0-Q1l9gYwEXqxCWqi1p1-3aNbj-tlTyrnclDMENYAxlm_qIoUbz4wMtjUblvImSjuqpaf91Y6iOrAFKnNslkSWQR9NuPceioKuQurUFsQVgbyorbFlzzklFiK7R75YX4iowQAvW5Vwm-ikv-D73CjR4C4VcS3iDaNiaQAqarT53Ff1ikragBJOAdYHhlDa1S4"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG71RBm7Ox2Lm_FZTtjZP6i_R8TzDUOi-GS6U75ZPc71dICyojw7KRDCyt5Iejb1kUea0cUYqmLvZKHYLiod8Dv1qd0s5WYnkGIXwvfvnLcOxagJe-gXx4zd2mWvLThxJFqvuJPc-C61xTS0yN1dSEvzcni23a_8I6cPI8iQ58qBAli3zaIz7o="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-12",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGkLXU6oNhUKG_GRt-lBltrhAVABq_wA2SwXig0GSPk5K0QbegcDCCXBh2jtxOBn91bbCJJFiI4-4YNmFjQvKt6rgRtzTWHmcNhxMEYEbVFF_Hzj5EosqGhtl0yZh8="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-13",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF-oFuTh-rWGuuTSbiYhPlFHEpm9TcpbstQqlJVQTgmtGQPdki86FQLjXvzFnd2YCiORH6yHRnA7d803UgM_YRl1tipH5QCSUIIubCYcim7p3l9DLV3O6yDhvE="
      },
      {
        "label": "medium",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-8",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHyRS5fMEJjhpu8b4l70Vrl8Igca3mIpiF-yRpW56hFOG1Wlgtpvj7zK-CHQn7f0FPsHkhfLt7MD1gW95QMZjqBTlgLtN7wL3KjYN3rTkE9oFZNUkSowTUbzxtT3C_9xIiGVLROC9A7Q6VvIrICUkcZQldbHeYhNb9dQmFF5Q3smBfad0L68u08Fbe3S_Lmxqq0C_dY5s2tcKgNTOcKby60fvHHaZfl"
      },
      {
        "label": "ycombinator",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJu6EXr2tXNvB-q6XH5-YvnVKNmt90NarymKYytwTkBPo4knNnMLEtJCTIyld4ARlAC7NV2uhxPCLO5nyndIelg-g3Ft729_Acg6GWKVPwUfREHUmlKWrU0EgE9TdELE45WjKh5Fl1"
      },
      {
        "label": "pugetsystems",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZtZ1rRX8FPNlxaCrKPJu5oYcWL1gGir4MBYdj_BQZTvvFun4lKadvOXkrSCSNaTnpfKJJQLf0ZbyISYtFkXrg1rY-WlNR2YmfbSgfoKyPP90wfMSMuFT40Pb1rt3GvKSpP3lNthYoRRnxns8SiEAeWm6ZuNXsvcBeKuQsMgHiae-XN4LwPH0="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-14",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE7vMGiV8q_LDOyCoOcjVZbL_7IitXYaELqh6y_Pz8YBsdWZr4YnmX-rwLzVwgh8tr6BCb_-ua8IH7dfXqzhcpABB3DMzMHmYjMyUBikBW3okMfTugzGZ5CsnmSYr8="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvlVtZ-TfFHfX0-Q1l9gYwEXqxCWqi1p1-3aNbj-tlTyrnclDMENYAxlm_qIoUbz4wMtjUblvImSjuqpaf91Y6iOrAFKnNslkSWQR9NuPceioKuQurUFsQVgbyorbFlzzklFiK7R75YX4iowQAvW5Vwm-ikv-D73CjR4C4VcS3iDaNiaQAqarT53Ff1ikragBJOAdYHhlDa1S4"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvlVtZ-TfFHfX0-Q1l9gYwEXqxCWqi1p1-3aNbj-tlTyrnclDMENYAxlm_qIoUbz4wMtjUblvImSjuqpaf91Y6iOrAFKnNslkSWQR9NuPceioKuQurUFsQVgbyorbFlzzklFiK7R75YX4iowQAvW5Vwm-ikv-D73CjR4C4VcS3iDaNiaQAqarT53Ff1ikragBJOAdYHhlDa1S4"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-9",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEYOvbTnUOceuSkL8OIVJ7t29daogwo3fg_vn5NGFpp62Wcan-pniEJZAKwfo4IKlqITkCixIHyPAcCkp8KrTgP8OCGTxtFUFP3Nj60BBiPOLZVCUIQioEkCyRDCtY3wtLg1R5dqjQb3h8NPORrwN013xUs8Oknu9T-jh1ywM-mI5yMumSLM9ZdRowUCQ=="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvlVtZ-TfFHfX0-Q1l9gYwEXqxCWqi1p1-3aNbj-tlTyrnclDMENYAxlm_qIoUbz4wMtjUblvImSjuqpaf91Y6iOrAFKnNslkSWQR9NuPceioKuQurUFsQVgbyorbFlzzklFiK7R75YX4iowQAvW5Vwm-ikv-D73CjR4C4VcS3iDaNiaQAqarT53Ff1ikragBJOAdYHhlDa1S4"
      },
      {
        "label": "ahelpme",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-15",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFpMO5JAxXQvBJrfJw0g8gLAhBuzR3teP9_RKP0MRYyk0KIkVMbi_Jk9YKMRDZ-A9P91uXTR2n6lYt5j8YGxrDL3p_OVkAZsQVINao4a2QdT1eULtdZP8kjfo4UQuK_sD_BbBFSxyFfCiOSUxA3TRkgeYoVX4Ejyrlo-JEU3UlsPvk8JLGtUjfeZ81rkq1c6g=="
      },
      {
        "label": "ahelpme",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-16",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGwQ68DpbuHybb_wQ_aVCBsxq9mJps80SGyqQXAvgFqR8D9hj2EpZ86jBZG7Dokmr5l30SYh8aOhZIaiuwuIMB6H218IAZNnkn5CFqFm731LnmxPvP9XedtsTcVlDB9Rb1oir3oQE6zyAuDSHctveP33gLWT0OZc76BeI86h9d8eLhaz6LuT5B2fxQRDf_p"
      },
      {
        "label": "reddit",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-17",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgOlnWo8Hu4dV0YPSQEM6L56sthBkOpjo8iqxy5CC-oMPSZGrHAAja1KeCIUiy_0jgzP9VVnH9UmXGF5UuFDorCDZytNE7CYqnRhcTRDCUzX5AZDF6eSxwF6NYNJMURI4bbnIZcBMEN6uDzxBgy8ppAO_zqLSKhk_O8D7TaG4xqLNRxBcEXw8E2zIMz-ZCk6sPS3S02CKtkdmx0KmjrA=="
      },
      {
        "label": "ahelpme",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-15",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFpMO5JAxXQvBJrfJw0g8gLAhBuzR3teP9_RKP0MRYyk0KIkVMbi_Jk9YKMRDZ-A9P91uXTR2n6lYt5j8YGxrDL3p_OVkAZsQVINao4a2QdT1eULtdZP8kjfo4UQuK_sD_BbBFSxyFfCiOSUxA3TRkgeYoVX4Ejyrlo-JEU3UlsPvk8JLGtUjfeZ81rkq1c6g=="
      },
      {
        "label": "pugetsystems",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZtZ1rRX8FPNlxaCrKPJu5oYcWL1gGir4MBYdj_BQZTvvFun4lKadvOXkrSCSNaTnpfKJJQLf0ZbyISYtFkXrg1rY-WlNR2YmfbSgfoKyPP90wfMSMuFT40Pb1rt3GvKSpP3lNthYoRRnxns8SiEAeWm6ZuNXsvcBeKuQsMgHiae-XN4LwPH0="
      },
      {
        "label": "ahelpme",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-16",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGwQ68DpbuHybb_wQ_aVCBsxq9mJps80SGyqQXAvgFqR8D9hj2EpZ86jBZG7Dokmr5l30SYh8aOhZIaiuwuIMB6H218IAZNnkn5CFqFm731LnmxPvP9XedtsTcVlDB9Rb1oir3oQE6zyAuDSHctveP33gLWT0OZc76BeI86h9d8eLhaz6LuT5B2fxQRDf_p"
      },
      {
        "label": "pugetsystems",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZtZ1rRX8FPNlxaCrKPJu5oYcWL1gGir4MBYdj_BQZTvvFun4lKadvOXkrSCSNaTnpfKJJQLf0ZbyISYtFkXrg1rY-WlNR2YmfbSgfoKyPP90wfMSMuFT40Pb1rt3GvKSpP3lNthYoRRnxns8SiEAeWm6ZuNXsvcBeKuQsMgHiae-XN4LwPH0="
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-2",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG71RBm7Ox2Lm_FZTtjZP6i_R8TzDUOi-GS6U75ZPc71dICyojw7KRDCyt5Iejb1kUea0cUYqmLvZKHYLiod8Dv1qd0s5WYnkGIXwvfvnLcOxagJe-gXx4zd2mWvLThxJFqvuJPc-C61xTS0yN1dSEvzcni23a_8I6cPI8iQ58qBAli3zaIz7o="
      },
      {
        "label": "ycombinator",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-3",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJu6EXr2tXNvB-q6XH5-YvnVKNmt90NarymKYytwTkBPo4knNnMLEtJCTIyld4ARlAC7NV2uhxPCLO5nyndIelg-g3Ft729_Acg6GWKVPwUfREHUmlKWrU0EgE9TdELE45WjKh5Fl1"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-1",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvlVtZ-TfFHfX0-Q1l9gYwEXqxCWqi1p1-3aNbj-tlTyrnclDMENYAxlm_qIoUbz4wMtjUblvImSjuqpaf91Y6iOrAFKnNslkSWQR9NuPceioKuQurUFsQVgbyorbFlzzklFiK7R75YX4iowQAvW5Vwm-ikv-D73CjR4C4VcS3iDaNiaQAqarT53Ff1ikragBJOAdYHhlDa1S4"
      },
      {
        "label": "pugetsystems",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-4",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZtZ1rRX8FPNlxaCrKPJu5oYcWL1gGir4MBYdj_BQZTvvFun4lKadvOXkrSCSNaTnpfKJJQLf0ZbyISYtFkXrg1rY-WlNR2YmfbSgfoKyPP90wfMSMuFT40Pb1rt3GvKSpP3lNthYoRRnxns8SiEAeWm6ZuNXsvcBeKuQsMgHiae-XN4LwPH0="
      },
      {
        "label": "andrewkchan",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-18",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEzPy8DDrIO5uj1fCgWpNilO6kas3okknHpWgQkyW9kId2AgWqZ2KOQr4SdpbXU4cztVMNdKoHWDKCHpYN_TFVTRc4qrXsmR56-HFG4NwqNKv24jroXUeMvdQHaUH10z5qK"
      },
      {
        "label": "amd",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-0",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEEyj0Z0P_4VQ9LAyUP29ptg1o62MjVnAPNl3inogoHXGhspsd2qRO2sB_1PJJwVaBiNTHJd9Nxmu3NCZIj7Uyzv8oMjB4lswh99wgAfzjlWjLbfQaYY0ACtRbHfrWUJv8dXPdFKhKqL1Sifcr4n4F9FyQieBshlp8UqdU_TqntXlXmIyr9gQe0m-WINj2IW72epjgfFdb520IWKFjv7RhUCbk7PEVr3oMjbYoRWq6du9WqJVKzaNT1eZLN9buK8I4-L2U="
      },
      {
        "label": "arxiv",
        "short_url": "https://vertexaisearch.cloud.google.com/id/1-12",
        "value": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGkLXU6oNhUKG_GRt-lBltrhAVABq_wA2SwXig0GSPk5K0QbegcDCCXBh2jtxOBn91bbCJJFiI4-4YNmFjQvKt6rgRtzTWHmcNhxMEYEbVFF_Hzj5EosqGhtl0yZh8="
      }
    ],
    "initial_search_query_count": "3",
    "max_research_loops": "3",
    "research_loop_count": "2"
  }
}