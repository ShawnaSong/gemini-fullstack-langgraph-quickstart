{'messages': [HumanMessage(content='ollama可以选择模型的不同量化版本吗？', additional_kwargs={}, response_metadata={}, id='6bf1a5a4-5dcb-4384-b561-5d457ecbcab2'), AIMessage(content='Yes, Ollama allows you to choose different quantization versions of models. Quantization is a technique used to reduce the size and computational demands of large language models (LLMs), making them suitable for a wider range of hardware [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0) [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1). Ollama utilizes GGML\'s GGUF algorithm for quantization, leveraging `llama.cpp` in the background [medium](https://vertexaisearch.cloud.google.com/id/0-3).\n\nHere\'s a breakdown of quantization options in Ollama:\n\n*   **Quantization Levels and Formats:** Ollama supports various quantization levels, often expressed as simple flags [medium](https://vertexaisearch.cloud.google.com/id/0-4). The number after the "q" represents the number of bits used for quantization (e.g., q4 means 4-bit quantization) [ollama](https://vertexaisearch.cloud.google.com/id/0-5) [ollama](https://vertexaisearch.cloud.google.com/id/0-6). Common quantization formats include [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1):\n    *   `Q8_0`: 8-bit integer quantization with maximum accuracy.\n    *   `Q5_K`: 5-bit grouped quantization focused on low memory usage.\n    *   `IQ3_M`: A quantization approach that balances speed, compression, and accuracy.\n    *   `Q4_K_M`: A commonly used quantization method [medium](https://vertexaisearch.cloud.google.com/id/0-4).\n    *   Ollama is also pioneering INT4 (4-bit) and INT2 (2-bit) quantization methods [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0).\n\n*   **Trade-offs:** It\'s important to consider the trade-offs between accuracy, model size, and performance [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2) [runpod](https://vertexaisearch.cloud.google.com/id/0-7]. Lower quantization levels result in smaller models and faster inference but may sacrifice some accuracy [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2) [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1). The best quantization level depends on the available hardware, especially VRAM [reddit](https://vertexaisearch.cloud.google.com/id/0-8].\n\n*   **How to Run Quantized Models:** You can run a quantized model from Hugging Face using the syntax: `ollama run hf.co/{username}/{repository}:{quantization}` [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n\nKeep in mind that while quantization reduces model size and increases speed, it can also reduce accuracy [mlexpert](https://vertexaisearch.cloud.google.com/id/1-1) [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6). It\'s crucial to test different quantization levels to find the best balance between performance and accuracy for your specific use case [youtube](https://vertexaisearch.cloud.google.com/id/1-8).', additional_kwargs={}, response_metadata={}, id='37539da2-078a-47b8-accf-7d755e8bba6a')], 'search_query': ['ollama model quantization options', 'What are the specific steps and commands to quantize a model using Ollama, including choosing different quantization levels and formats?', 'What is the impact of different quantization methods (e.g., Q8_0, Q5_K, IQ3_M, Q4_K_M, INT4, INT2) on model accuracy, inference speed, and memory usage in Ollama, with quantitative benchmarks where available?', 'How does Ollama manage VRAM when using different quantization levels, and what are the best practices for optimizing memory usage on different hardware configurations?'], 'web_research_result': ['Okay, I will conduct Google Searches to gather the most recent information on "ollama model quantization options" and synthesize it into a verifiable text artifact.\nOllama is a platform that simplifies the local deployment of large language models (LLMs), emphasizing privacy, performance, and customization [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0). Quantization is a key technique used by Ollama to reduce the size and computational demands of LLMs, making them suitable for a wider range of hardware [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0) [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1).\n\n**What is Quantization?**\n\nQuantization is the process of converting model weights (parameters) into lower-precision integer formats, typically from 16 or 32-bit floating-point numbers to 8-bit or smaller integers [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2). This significantly reduces the model size (by 4x or more), lowers memory requirements, and increases inference speed [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1) [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2).\n\n**Quantization Options and Formats**\n\nOllama utilizes the GGML\'s GGUF algorithm for quantization, leveraging llama.cpp in the background [medium](https://vertexaisearch.cloud.google.com/id/0-3). GGUF (GPT-Generated Unified Format) is a model version optimized for local machine inference [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1). Ollama supports various quantization levels, which are often expressed as simple flags [medium](https://vertexaisearch.cloud.google.com/id/0-4). The number after the "q" represents the number of bits used for quantization (e.g., q4 means 4-bit quantization) [ollama](https://vertexaisearch.cloud.google.com/id/0-5) [ollama](https://vertexaisearch.cloud.google.com/id/0-6). Common quantization formats include [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1):\n\n*   **Q8\\_0:** 8-bit integer quantization with maximum accuracy.\n*   **Q5\\_K:** 5-bit grouped quantization focused on low memory usage.\n*   **IQ3\\_M:** A quantization approach that balances speed, compression, and accuracy.\n*   **Q4\\_K\\_M**: A commonly used quantization method [medium](https://vertexaisearch.cloud.google.com/id/0-4).\n\nOllama is also pioneering INT4 (4-bit) and INT2 (2-bit) quantization methods [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0).\n\n**Trade-offs**\n\nWhile quantization offers numerous benefits, it\'s important to consider the trade-offs [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2) [runpod](https://vertexaisearch.cloud.google.com/id/0-7):\n\n*   **Accuracy:** Quantization can lead to some loss of accuracy, especially with very low bit quantization (e.g., 3-bit or lower) [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2). However, the accuracy loss can be negligible within a certain range (e.g., 8-bit to 4-bit) [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2).\n*   **Model Size vs. Performance:** There\'s a trade-off between model size, speed, and accuracy [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2). Lower quantization levels result in smaller models and faster inference but may sacrifice some accuracy [mlexpert](https://vertexaisearch.cloud.google.com/id/0-2) [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/0-1).\n*   **Hardware:** The best quantization level depends on the available hardware, especially VRAM [reddit](https://vertexaisearch.cloud.google.com/id/0-8). It\'s generally recommended to choose a quantization level that allows the entire model and context window to fit within the VRAM to avoid performance penalties [reddit](https://vertexaisearch.cloud.google.com/id/0-8).\n\n**Best Practices and Recommendations**\n\n*   **Model Selection:** Quantization allows larger models to run on smaller GPUs, but a quantized model might not have the same detail or accuracy as a full-precision model [runpod](https://vertexaisearch.cloud.google.com/id/0-7).\n*   **Test and Evaluate:** It\'s crucial to test different quantization levels with your specific use case to determine the optimal balance between performance and accuracy [medium](https://vertexaisearch.cloud.google.com/id/0-9).\n*   **Consider Model Size:** The impact of quantization on output quality is less significant for larger models (e.g., 70B parameters) compared to smaller models (e.g., 1.3B or 3B parameters) [reddit](https://vertexaisearch.cloud.google.com/id/0-8).\n*   **Use QX\\_K Quants:** It is recommended to use "QX_K" quants instead of older quants with Qx\\_0 and Qx\\_1 [reddit](https://vertexaisearch.cloud.google.com/id/0-8).\n*   **KV Cache Quantization:** Using Q8 quantization for the KV cache (by setting `export OLLAMA_KV_CACHE_TYPE=q8_0`) can halve the memory requirements compared to the default FP16, allowing you to work with longer contexts [medium](https://vertexaisearch.cloud.google.com/id/0-9). However, this doesn\'t work well with every model, so testing is essential [medium](https://vertexaisearch.cloud.google.com/id/0-9).\n*   **Start with Q4KM:** Begin with a Q4KM model, enable flash attention, and test your specific use case. If it runs smoothly, try Q2. If there are issues, move to Q8 [youtube](https://vertexaisearch.cloud.google.com/id/0-10).\n\n**Ollama in 2025**\n\nOllama has become a dominant platform for local LLM deployment due to its advanced quantization engine, memory management capabilities, hardware acceleration, and API compatibility [collabnix](https://vertexaisearch.cloud.google.com/id/0-11). Ollama is pioneering INT4 and INT2 quantization methods, which further compress model weights and reduce memory footprint [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0). The platform supports a wide range of models, including source models, fine-tuned models, embedding models, and multimodal models [elightwalk](https://vertexaisearch.cloud.google.com/id/0-0).\n', 'To quantize a model using Ollama, here\'s a breakdown of the process, including the steps, commands, quantization levels, and formats:\n\n**1. Understanding Quantization**\n\n*   Quantization reduces the computational resources needed to run Large Language Models (LLMs) [medium](https://vertexaisearch.cloud.google.com/id/1-0).\n*   It makes models smaller and faster [mlexpert](https://vertexaisearch.cloud.google.com/id/1-1) [medium](https://vertexaisearch.cloud.google.com/id/1-2).\n*   This is achieved by reducing the numerical precision of the model\'s parameters (weights), typically from 32-bit floating-point to lower representations like 8-bit integers [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n*   Quantization allows large language models (LLMs) to be deployed under resource-constrained settings, such as local machines, mobile devices, or edge servers [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n*   Benefits include reduced memory usage, faster inference, and lower computational costs [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3) [medium](https://vertexaisearch.cloud.google.com/id/1-0).\n*   Ollama supports the GGML\'s GGUF algorithm for quantization, utilizing `llama.cpp` in the background [medium](https://vertexaisearch.cloud.google.com/id/1-2). This approach can convert models from Hugging Face into 2-bit to 8-bit variants [medium](https://vertexaisearch.cloud.google.com/id/1-2).\n\n**2. Installation**\n\n*   First, ensure you have Ollama installed on your local machine [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3). Download the compatible version for your operating system from the official website [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n*   You can check if the Ollama server is running by typing `http://localhost:11434/` in your browser. If it\'s running, you should see a message like "Ollama is running" [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n\n**3. Quantization Levels and Formats**\n\n*   Ollama uses 4-bit quantization by default [ollama](https://vertexaisearch.cloud.google.com/id/1-4) [ollama](https://vertexaisearch.cloud.google.com/id/1-5).\n*   The number after the \'q\' represents the number of bits used for quantization (e.g., `q4` means 4-bit quantization) [ollama](https://vertexaisearch.cloud.google.com/id/1-5) [ollama](https://vertexaisearch.cloud.google.com/id/1-4).\n*   Generally, a higher number indicates a more accurate model but slower performance and higher memory requirements [ollama](https://vertexaisearch.cloud.google.com/id/1-5) [ollama](https://vertexaisearch.cloud.google.com/id/1-4).\n*   Available quantization formats include [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3):\n    *   `Q8_0`: 8-bit integer quantization with maximum accuracy.\n    *   `Q5_K`: 5-bit grouped quantization focused on low memory usage.\n    *   `IQ3_M`: A quantization approach that balances speed, compression, and accuracy.\n*   Other quantization levels are also available [ollama](https://vertexaisearch.cloud.google.com/id/1-5) [ollama](https://vertexaisearch.cloud.google.com/id/1-4).\n\n**4. Quantizing a Model**\n\n*   Ollama can quantize FP16 and FP32 based models into different quantization levels using the `-q/--quantize` flag with the `ollama create` command [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6).\n*   Create a `Modelfile` with the FP16 or FP32 based model you wish to quantize [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6).\n*   Use `ollama create` to then create the quantized model [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6).\n\n**5. Running a Quantized Model from Hugging Face**\n\n*   To run a quantized model from Hugging Face, use the following syntax: `ollama run hf.co/{username}/{repository}:{quantization}` [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n    *   For example: `ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF` [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n*   This command pulls and runs a Hugging Face model into Ollama [machinelearningmastery](https://vertexaisearch.cloud.google.com/id/1-3).\n\n**6. Steps for Quantization with `llama.cpp` (if needed)**\n\n*   These steps are involved if you want to convert a model manually using `llama.cpp` [medium](https://vertexaisearch.cloud.google.com/id/1-2):\n    1.  Clone the `llama.cpp` repository:\n        ```bash\n        git clone https://github.com/ggerganov/llama.cpp.git\n        ```\n    2.  Set up Python and a virtual environment:\n        ```bash\n        python3.10 -m venv ~venv/llama_cpp\n        source ~/venv/llama_cpp/bin/activate\n        ```\n    3.  Install the required Python packages:\n        ```bash\n        pip install -r llama.cpp/requirements.txt\n        ```\n    4.  Compile the quantization program:\n        ```bash\n        make -C llama.cpp llama-quantize\n        ```\n    5.  Download a model from Hugging Face:\n        ```bash\n        huggingface-cli download Qwen/Qwen2-7B-Instruct\n        ```\n    6.  Convert the model to GGML FP16 format:\n        ```bash\n        MODEL_NAME="Qwen2-7B-Instruct"\n        python3 convert_hf_to_gguf.py models/$MODEL_NAME\n        ```\n    7.  Execute quantization with the `llama-quantize` tool:\n        ```bash\n        QUANT="Q4_K_M"\n        ./llama-quantize ./models/$MODEL_NAME/ggml-model-f16.gguf ./models/$MODEL_NAME/ggml-model-Q4_K_M.gguf $QUANT\n        ```\n\n**7. Using a Modelfile**\n\n*   Create a `Modelfile` [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6).\n*   To import a Safetensors model, the `FROM` command should point to the directory containing your Safetensors weights [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6):\n    ```\n    FROM /path/to/safetensors/directory\n    ```\n    If the `Modelfile` is in the same directory as the weights:\n    ```\n    FROM .\n    ```\n*   To import a fine-tuned adapter, use the `ADAPTER` command [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6):\n    ```\n    FROM <base model name>\n    ADAPTER /path/to/safetensors/adapter/directory\n    ```\n    If the adapter is in the same directory as your `Modelfile`:\n    ```\n    ADAPTER .\n    ```\n*   Create the model using the `ollama create` command [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6):\n    ```bash\n    ollama create my-model -f Modelfile\n    ```\n*   Test the model [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6):\n    ```bash\n    ollama run my-model\n    ```\n\n**8. Important Considerations**\n\n*   **Accuracy Trade-off:** Quantization reduces model size and increases speed, but it can also reduce accuracy [mlexpert](https://vertexaisearch.cloud.google.com/id/1-1) [readthedocs](https://vertexaisearch.cloud.google.com/id/1-6). The loss in accuracy can be negligible within a certain quantization range (8-bit to 4-bit) [mlexpert](https://vertexaisearch.cloud.google.com/id/1-1).\n*   **VRAM Requirement:** Choose a quantization level that fits your VRAM. If the model doesn\'t fit entirely in VRAM, performance will be significantly reduced [reddit](https://vertexaisearch.cloud.google.com/id/1-7).\n*   **Regularly Update Models:**  Repull models regularly to get the latest versions [youtube](https://vertexaisearch.cloud.google.com/id/1-8).\n*   **Experimentation:** It\'s important to test different quantization levels to find the best balance between performance and accuracy for your specific use case [youtube](https://vertexaisearch.cloud.google.com/id/1-8).\n', "Quantization is a crucial technique used in Ollama to reduce the size and computational demands of large language models (LLMs) without significantly compromising their accuracy [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0) [collabnix](https://vertexaisearch.cloud.google.com/id/2-1). It involves converting weights and biases from high-precision floating-point values to lower-precision representations [medium](https://vertexaisearch.cloud.google.com/id/2-2). Ollama pioneers INT4 (4-bit) and INT2 (2-bit) quantization methods, compressing model weights far beyond the standard 8-bit or 16-bit precision [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0).\n\n**Impact of Quantization Levels on Model Performance:**\n\nDifferent quantization levels offer varying trade-offs between model accuracy, inference speed, and memory usage [youtube](https://vertexaisearch.cloud.google.com/id/2-3). Here's a summary of how different quantization levels impact these factors:\n\n*   **INT2 (2-bit):** This extreme option feels like pure magic [youtube](https://vertexaisearch.cloud.google.com/id/2-4). It offers the smallest model size and fastest inference speed, making it suitable for devices with extreme memory constraints [youtube](https://vertexaisearch.cloud.google.com/id/2-4) [youtube](https://vertexaisearch.cloud.google.com/id/2-3) [collabnix](https://vertexaisearch.cloud.google.com/id/2-1). However, it significantly reduces accuracy [youtube](https://vertexaisearch.cloud.google.com/id/2-3). In some cases, a 2-bit quantization can generate an answer in about 2 seconds, while a 4-bit quantization takes 3 seconds, and a 16-bit floating-point weight takes 10 seconds [youtube](https://vertexaisearch.cloud.google.com/id/2-4).\n*   **INT4 (4-bit):** Models become significantly smaller, reducing memory footprint and storage requirements [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0). Lower precision calculations translate into faster inference times and lower energy consumption [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0). It is more than adequate for most needs [youtube](https://vertexaisearch.cloud.google.com/id/2-4). However, some people say that 4-bit quantization of any model is useless [youtube](https://vertexaisearch.cloud.google.com/id/2-4).\n*   **Q4\\_K\\_M:** This is considered a standard quantization that offers a good balance between size, speed, and accuracy [collabnix](https://vertexaisearch.cloud.google.com/id/2-1) [youtube](https://vertexaisearch.cloud.google.com/id/2-3).\n*   **Q5\\_K\\_M:** It provides an optimal balance for most users [collabnix](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Q6\\_K:** It retains good quality while reducing memory [collabnix](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **Q8\\_0:** At a quantization of Q8_0, the time it takes to run through all the questions is 41 minutes, while Q6_K takes 25 minutes [substack](https://vertexaisearch.cloud.google.com/id/2-5). Quantization made inference around 40% faster [substack](https://vertexaisearch.cloud.google.com/id/2-5). It offers balanced accuracy and efficiency [collabnix](https://vertexaisearch.cloud.google.com/id/2-1).\n*   **FP16 (16-bit Floating Point):** It gives maximum accuracy and requires high VRAM [collabnix](https://vertexaisearch.cloud.google.com/id/2-1).\n\n**Benefits of Quantization in Ollama:**\n\n*   **Reduced Memory Footprint:** Quantization reduces the size of models, which lowers memory footprint and storage requirements [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0).\n*   **Faster Inference Times:** Lower precision calculations translate into faster inference times and lower energy consumption [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0). Coarser quantization types yield the best speed [medium](https://vertexaisearch.cloud.google.com/id/2-2).\n*   **Efficient Resource Utilization:** Ollama uses advanced optimization techniques such as INT4/INT2 quantization, streaming KV-cache, multi-GPU pipeline parallelism, and dynamic batching [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0). These methods enhance inference speed and support smooth AI operations on both high-end and edge devices [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0).\n*   **Dynamic Model Management:** Ollama's newer releases (v0.8.0+) come with improved memory management and model swapping, allowing automatic unloading/loading of models based on active use [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0).\n\n**Other Considerations:**\n\n*   The impact of quantization on accuracy is two-fold: the model starts to answer questions incorrectly, and the model starts to fail to answer at all [substack](https://vertexaisearch.cloud.google.com/id/2-5).\n*   The transition point for small accuracy loss to big happens when going below Q3 quantization [substack](https://vertexaisearch.cloud.google.com/id/2-5).\n*   With current Nvidia hardware, not natively supporting 4-bit calculations, there is no performance gain to be had with quantization below 8-bits, other than for the purpose of reducing memory usage [substack](https://vertexaisearch.cloud.google.com/id/2-5).\n*   Once the entire model fits within the GPU memory, no further performance is gained from additional quantization [substack](https://vertexaisearch.cloud.google.com/id/2-5).\n*   Models like Phi-4, Moondream 1.8B, and Mistral-7B-Instruct are optimized for lightweight environments and use quantization techniques and reduced parameter sizes, making them ideal for CPUs, mobile devices, or laptops with limited RAM and VRAM [elightwalk](https://vertexaisearch.cloud.google.com/id/2-0).\n*   Generally speaking, the lower the quantization, the higher the perplexity of the model (how drunk it is compared to the original model) [reddit](https://vertexaisearch.cloud.google.com/id/2-6).\n*   The more parameters a model has, the less quantization impacts the output quality [reddit](https://vertexaisearch.cloud.google.com/id/2-6).\n*   It's better to download a model with quantization that fits the VRAM; otherwise, part of it will be placed in RAM with a significant performance penalty [reddit](https://vertexaisearch.cloud.google.com/id/2-6).\n", "Ollama manages VRAM usage through several techniques, including quantization, K/V cache optimization, and collaboration with hardware manufacturers [ollama](https://vertexaisearch.cloud.google.com/id/3-0) [broadcom](https://vertexaisearch.cloud.google.com/id/3-1). Effective VRAM management is crucial for running large language models (LLMs) efficiently, especially on systems with limited GPU memory [arsturn](https://vertexaisearch.cloud.google.com/id/3-2).\n\n**Quantization**\n\nQuantization reduces the precision of model parameters, converting them from 32-bit floating point to lower-precision formats like 16-bit (FP16), 8-bit (INT8), or even 4-bit integers [arsturn](https://vertexaisearch.cloud.google.com/id/3-2). This significantly decreases model size and memory requirements, making it possible to run larger models on consumer hardware [youtube](https://vertexaisearch.cloud.google.com/id/3-3).\n\n*   **Benefits:**\n    *   Reduces memory usage by 50-75% [medium](https://vertexaisearch.cloud.google.com/id/3-4).\n    *   Allows larger models to fit on GPUs with limited VRAM [medium](https://vertexaisearch.cloud.google.com/id/3-4).\n    *   Can improve inference speed [peddals](https://vertexaisearch.cloud.google.com/id/3-5).\n*   **Considerations:**\n    *   Lower quantization levels may impact model quality, especially for smaller models [reddit](https://vertexaisearch.cloud.google.com/id/3-6) [broadcom](https://vertexaisearch.cloud.google.com/id/3-1).\n    *   It's recommended to test different quantization levels to find the best balance between size and accuracy for a specific use case [medium](https://vertexaisearch.cloud.google.com/id/3-7).\n*   **Types:**\n    *   **f16:** Float16 precision, offering the highest accuracy but using more memory [broadcom](https://vertexaisearch.cloud.google.com/id/3-1).\n    *   **q8\\_0:** 8-bit quantization, reducing memory usage by ~50% with minimal quality impact [broadcom](https://vertexaisearch.cloud.google.com/id/3-1).\n    *   **q4\\_0:** 4-bit quantization, reducing memory usage by ~75% with moderate quality impact [broadcom](https://vertexaisearch.cloud.google.com/id/3-1).\n    *   **QX\\_K:** Newer quantization algorithms like Q4\\_K\\_M offer a better balance between size and quality compared to older methods like Qx\\_0 and Qx\\_1 [reddit](https://vertexaisearch.cloud.google.com/id/3-6).\n\n**K/V Cache Optimization**\n\nOllama uses a Key-Value (K/V) cache to store precomputed attention vectors for previous tokens during model inference [broadcom](https://vertexaisearch.cloud.google.com/id/3-1). This prevents recalculating attention scores from scratch, speeding up response times and reducing computational costs [broadcom](https://vertexaisearch.cloud.google.com/id/3-1).\n\n*   **K/V Cache Quantization:** Applying quantization to the K/V cache can further reduce memory usage [peddals](https://vertexaisearch.cloud.google.com/id/3-5).\n    *   Using `export OLLAMA_KV_CACHE_TYPE=q8_0` enables Q8 quantization for the cache, effectively halving the memory requirements compared to the default FP16 [medium](https://vertexaisearch.cloud.google.com/id/3-7).\n    *   This allows working with longer contexts without running out of memory [medium](https://vertexaisearch.cloud.google.com/id/3-7).\n*   **Context Size:** Adjusting the context window size can also impact RAM usage [arsturn](https://vertexaisearch.cloud.google.com/id/3-8) [arsturn](https://vertexaisearch.cloud.google.com/id/3-2). Experimenting with smaller context windows can lead to faster response times without overly compromising the model's capabilities [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n*   **Sliding Window Attention (SWA):** Some models use SWA, which limits attention to a window of recent tokens, cutting KV memory growth [medium](https://vertexaisearch.cloud.google.com/id/3-4).\n\n**Hardware and System Configuration**\n\n*   **GPU Acceleration:** Utilizing NVIDIA GPUs with CUDA support (e.g., RTX 3080, RTX 4090) can significantly improve performance [anakin](https://vertexaisearch.cloud.google.com/id/3-9) [arsturn](https://vertexaisearch.cloud.google.com/id/3-8). GPUs with at least 8GB VRAM are recommended for smaller models, and 16GB+ VRAM for larger models [anakin](https://vertexaisearch.cloud.google.com/id/3-9).\n*   **CPU and RAM:** Upgrading to modern processors like Intel Core i9 or AMD Ryzen 9 with multiple cores and high clock speeds can help Ollama manage tasks better [anakin](https://vertexaisearch.cloud.google.com/id/3-9) [arsturn](https://vertexaisearch.cloud.google.com/id/3-8). Aim for at least 16GB of RAM for smaller models, 32GB for medium, and around 64GB for larger models [anakin](https://vertexaisearch.cloud.google.com/id/3-9) [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n*   **Memory Monitoring:** Use commands like `ollama ps` to monitor GPU memory usage [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n*   **Operating System:** Consider using a minimal Linux distribution like Ubuntu Server if running on limited VRAM [medium](https://vertexaisearch.cloud.google.com/id/3-7).\n*   **Flash Attention:** Enable Flash Attention by setting `export OLLAMA_FLASH_ATTENTION=1` to improve quality and performance when working with long contexts [medium](https://vertexaisearch.cloud.google.com/id/3-7). This optimization reduces memory usage during inference and works particularly well on modern GPUs [medium](https://vertexaisearch.cloud.google.com/id/3-7).\n\n**Best Practices for Optimizing Memory Usage**\n\n1.  **Monitor Memory Usage:** Understanding how models use memory is crucial [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n2.  **Optimize Model Loading:** Control which models are loaded at any given time [arsturn](https://vertexaisearch.cloud.google.com/id/3-8). Adjust the `OLLAMA_MAX_LOADED_MODELS` parameter to correspond with hardware capabilities [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n3.  **Employ Quantization Techniques:** Reduce the precision of numbers used in model computations [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n4.  **Limit GPU Memory Usage:** Balance the load across multiple GPUs if available [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n5.  **Implement Efficient Caching Strategies:** Cache frequently used models to load them quickly and with reduced overhead [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n6.  **Upgrade Hardware:** Enhance CPU power, increase RAM, and utilize a GPU if possible [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n7.  **Regular Updates and Optimizations:** Keep the Ollama installation updated to benefit from ongoing performance enhancements and bug fixes [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n8.  **Consider Context Size:** Experiment with smaller context windows to reduce RAM usage [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n9.  **Use Efficient Prompts:** Make prompts clear and concise to enhance how quickly and effectively Ollama responds [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n10. **Tune System Resources:** Disable unnecessary background processes and ensure the system is not thermal throttling [arsturn](https://vertexaisearch.cloud.google.com/id/3-10). Optimize storage settings for SSDs where models are loaded [arsturn](https://vertexaisearch.cloud.google.com/id/3-2).\n11. **VRAM Planning:** Choose a model that fits the available VRAM, use quantized formats, and estimate per-token KV cost to select an appropriate context size [medium](https://vertexaisearch.cloud.google.com/id/3-4).\n12. **Balance GPU and CPU Usage:** Avoid hybrid setups where too little is offloaded to the GPU, as this can be slower than pure CPU inference [medium](https://vertexaisearch.cloud.google.com/id/3-4).\n13. **Keep Drivers Updated:** Ensure GPU drivers are up to date to get the best performance [medium](https://vertexaisearch.cloud.google.com/id/3-7).\n\nBy implementing these strategies, users can maximize their system's efficiency and enjoy smooth performance when running large language models with Ollama [arsturn](https://vertexaisearch.cloud.google.com/id/3-8).\n"], 'sources_gathered': [{'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGtMzf_Ccu3nfeADyxqCspud-JWY5axIU-AG3Y_8z3ygbC1VP3hCASBWMDZVI1oHnGJ5WkT4gRIevUiReBqCS16MUuTZsANUQD7UD_fmbXz2408KTr07Sj31QQxhKPFGSXFSuOBiZnxe3dzt_nwc='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGtMzf_Ccu3nfeADyxqCspud-JWY5axIU-AG3Y_8z3ygbC1VP3hCASBWMDZVI1oHnGJ5WkT4gRIevUiReBqCS16MUuTZsANUQD7UD_fmbXz2408KTr07Sj31QQxhKPFGSXFSuOBiZnxe3dzt_nwc='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHy6D2PjoDJkqK1qNOjGmc_REcSMklVr8EC0fBDSUPbOyp3RfEHUJ0FseU4KbPopfTeBumP3nIzBo_RSDOdLAFYW8YE_FBl__cJ8xL3zM8hNREA-g2qWwhxPsaaJ2iZmVux10U6Z-FA-U6MAEXndCXW-KPdMWvt9DJxNYKSusAPyG5NbqPfQc_CA2pHw5qZcxC7ms5g5ZjdvzrzTlPu'}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHy6D2PjoDJkqK1qNOjGmc_REcSMklVr8EC0fBDSUPbOyp3RfEHUJ0FseU4KbPopfTeBumP3nIzBo_RSDOdLAFYW8YE_FBl__cJ8xL3zM8hNREA-g2qWwhxPsaaJ2iZmVux10U6Z-FA-U6MAEXndCXW-KPdMWvt9DJxNYKSusAPyG5NbqPfQc_CA2pHw5qZcxC7ms5g5ZjdvzrzTlPu'}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGkTpsSyNv5yYs7OA9ACXQnOMWMcuyxoPEz7j5Wy2FcOAFWtXHuQriqsRkfpKbw3gjiz7CIBnGRTM3gYMOzD6vSSllziS06sP0NcCnLIuZjyxr5mjL51kj3a7WXAoZA61nABW5FNjFxCU-3_ArxTGHccn57Ph4fqOZZTzBGqOEDYA=='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHy6D2PjoDJkqK1qNOjGmc_REcSMklVr8EC0fBDSUPbOyp3RfEHUJ0FseU4KbPopfTeBumP3nIzBo_RSDOdLAFYW8YE_FBl__cJ8xL3zM8hNREA-g2qWwhxPsaaJ2iZmVux10U6Z-FA-U6MAEXndCXW-KPdMWvt9DJxNYKSusAPyG5NbqPfQc_CA2pHw5qZcxC7ms5g5ZjdvzrzTlPu'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGwAp97WJfwnymKuR1zw02FsOrRi9RajQkaql8o4ZYqMDvwXK7CXQEcYrPDq-Cm6-tsfAJToU_yWtJBz30PxaJ_Xx7DL8Z1J47xthmxaQ2qeyCOsVhgl9bb4WE7uo5us5KnfDawIGaNW3nU6PIoZeWYAAEb8jPVt7WLC1Ru76LVB6aqS4AMSEb8NkwG7cPVkH2RXVPUulFNYd4V8L87gsJhYEKPrqf9N3O7kQNnlkIsxg=='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFt7KKSEUBOOUAMhusgUuwZncy7BBAqXpmTJG0yQjV9Nx5ne4ee-I2SRkwEkFI94ihW68h8umpZAbuNS6peaz8CDQqsvGH_TkZb6wdmMk3vFMxvjb6q4vLhYJXlQbPH'}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGds2TiJaD_5eqpAVBK6Q_InTtYPy-LDnQSjIi5yQkFPSeAzKRe_IRJZTRS_albqdzjwbsgmP2pgc5Zzh022UsD50Drje3HGbgvpZ6fgHqNKXPzBjTD61vwYwKYnA=='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHy6D2PjoDJkqK1qNOjGmc_REcSMklVr8EC0fBDSUPbOyp3RfEHUJ0FseU4KbPopfTeBumP3nIzBo_RSDOdLAFYW8YE_FBl__cJ8xL3zM8hNREA-g2qWwhxPsaaJ2iZmVux10U6Z-FA-U6MAEXndCXW-KPdMWvt9DJxNYKSusAPyG5NbqPfQc_CA2pHw5qZcxC7ms5g5ZjdvzrzTlPu'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGwAp97WJfwnymKuR1zw02FsOrRi9RajQkaql8o4ZYqMDvwXK7CXQEcYrPDq-Cm6-tsfAJToU_yWtJBz30PxaJ_Xx7DL8Z1J47xthmxaQ2qeyCOsVhgl9bb4WE7uo5us5KnfDawIGaNW3nU6PIoZeWYAAEb8jPVt7WLC1Ru76LVB6aqS4AMSEb8NkwG7cPVkH2RXVPUulFNYd4V8L87gsJhYEKPrqf9N3O7kQNnlkIsxg=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGtMzf_Ccu3nfeADyxqCspud-JWY5axIU-AG3Y_8z3ygbC1VP3hCASBWMDZVI1oHnGJ5WkT4gRIevUiReBqCS16MUuTZsANUQD7UD_fmbXz2408KTr07Sj31QQxhKPFGSXFSuOBiZnxe3dzt_nwc='}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'runpod', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFtt0S1ReD2zWFcwOq9QR2qqEpmgX9kVsB48FPz5djJsowRB8coqEDD2tJVHz3ODsy5rYPH4AFw3J2vIoA3mEcSPnugvVyw2L-XRxU0mH2zRG5O6rnuTQ5_j8YqPXYys5z5TV1UvCeG-fIkMeq--cgSIoVBorYiXunwoMIDOvgKQ-nL8jOlm4NPa-V9HA=='}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0d_LHFHRCuzcTw5XerK-mmFd5gRB7grBUEO_1JLO9F7DvXzyqWNfMG2PlXfWVv7QcNvPnQMpoehuw7kC_SxdcwR_fOTpftQ1kGu-6mZF-88wVTLZkhGXYX7tNG1U1nFXz0Ef7TQPU9ATm9yoo'}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHy6D2PjoDJkqK1qNOjGmc_REcSMklVr8EC0fBDSUPbOyp3RfEHUJ0FseU4KbPopfTeBumP3nIzBo_RSDOdLAFYW8YE_FBl__cJ8xL3zM8hNREA-g2qWwhxPsaaJ2iZmVux10U6Z-FA-U6MAEXndCXW-KPdMWvt9DJxNYKSusAPyG5NbqPfQc_CA2pHw5qZcxC7ms5g5ZjdvzrzTlPu'}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEkXFMQtAhZ8yPS206naP6-zkFXf9O9HK8L6b4rfsDBFmS8tw8vnMBNVE3sITBPK9pQFFOcuc_pXVXWe2XvogwLaVey0vaMgazDlf3YWYOlsRX5foJHwHHHnuMmQCBBB-r7qS2-aBJp0x6JO9XTBvnya4kORs8XgzTd4Qj0Ddvl4YvoYHoc3cARQGXXqiLFIREvD0miJ7M='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEkXFMQtAhZ8yPS206naP6-zkFXf9O9HK8L6b4rfsDBFmS8tw8vnMBNVE3sITBPK9pQFFOcuc_pXVXWe2XvogwLaVey0vaMgazDlf3YWYOlsRX5foJHwHHHnuMmQCBBB-r7qS2-aBJp0x6JO9XTBvnya4kORs8XgzTd4Qj0Ddvl4YvoYHoc3cARQGXXqiLFIREvD0miJ7M='}, {'label': 'runpod', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFtt0S1ReD2zWFcwOq9QR2qqEpmgX9kVsB48FPz5djJsowRB8coqEDD2tJVHz3ODsy5rYPH4AFw3J2vIoA3mEcSPnugvVyw2L-XRxU0mH2zRG5O6rnuTQ5_j8YqPXYys5z5TV1UvCeG-fIkMeq--cgSIoVBorYiXunwoMIDOvgKQ-nL8jOlm4NPa-V9HA=='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG97gdnkSvll8L9thm3L0jQNmmeKyb5IJTL8LladPXf8LdDgoSFZquXHuKxkB6zdq_huiMnrZ9JzxDKep28pdeMVDL7TsWSx7zXH0I4xV6kaolnVd9CIUxy7R87Bo_4DJs7hiMWy1wsigmp9kktbsOm_zd2Vqt3F4SkWzKOAYnMYfVXm3-aRk99KFRfLaOeJ1fAfK8OA3s216qm2Kpq3r1nhjv8'}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEkXFMQtAhZ8yPS206naP6-zkFXf9O9HK8L6b4rfsDBFmS8tw8vnMBNVE3sITBPK9pQFFOcuc_pXVXWe2XvogwLaVey0vaMgazDlf3YWYOlsRX5foJHwHHHnuMmQCBBB-r7qS2-aBJp0x6JO9XTBvnya4kORs8XgzTd4Qj0Ddvl4YvoYHoc3cARQGXXqiLFIREvD0miJ7M='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEkXFMQtAhZ8yPS206naP6-zkFXf9O9HK8L6b4rfsDBFmS8tw8vnMBNVE3sITBPK9pQFFOcuc_pXVXWe2XvogwLaVey0vaMgazDlf3YWYOlsRX5foJHwHHHnuMmQCBBB-r7qS2-aBJp0x6JO9XTBvnya4kORs8XgzTd4Qj0Ddvl4YvoYHoc3cARQGXXqiLFIREvD0miJ7M='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG97gdnkSvll8L9thm3L0jQNmmeKyb5IJTL8LladPXf8LdDgoSFZquXHuKxkB6zdq_huiMnrZ9JzxDKep28pdeMVDL7TsWSx7zXH0I4xV6kaolnVd9CIUxy7R87Bo_4DJs7hiMWy1wsigmp9kktbsOm_zd2Vqt3F4SkWzKOAYnMYfVXm3-aRk99KFRfLaOeJ1fAfK8OA3s216qm2Kpq3r1nhjv8'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG97gdnkSvll8L9thm3L0jQNmmeKyb5IJTL8LladPXf8LdDgoSFZquXHuKxkB6zdq_huiMnrZ9JzxDKep28pdeMVDL7TsWSx7zXH0I4xV6kaolnVd9CIUxy7R87Bo_4DJs7hiMWy1wsigmp9kktbsOm_zd2Vqt3F4SkWzKOAYnMYfVXm3-aRk99KFRfLaOeJ1fAfK8OA3s216qm2Kpq3r1nhjv8'}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-10', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGi7Uli2hTtpre-1aODV3ETT7yi_XC8qjQy9BBUl0XNS2eSCoFo_cp1IMNh1n71qKXspawe3NBrlTjk9BXz1XnbdtwTnwfkxqJ5nS0jax9tQpwtjQJvxd-IrwWiQ-A-efL6I8jVpq0='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-11', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH9d6E9Nu8LZUaVx1peJESyQnCV4MMdmuy8G4L23985-6jV6qIvttu0NkclWHoqrtgUROCsXsRv-DCvgEp518B3SSMW3NcClaSLXNsPVh7yUHGSv4msEELb0VrD5B9Co_s3rTqPjK_txASonvUCEwfyF-wU1dBRjQKRc5ZRb5DPz10ohtpUqaVZIh1kfg=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGtMzf_Ccu3nfeADyxqCspud-JWY5axIU-AG3Y_8z3ygbC1VP3hCASBWMDZVI1oHnGJ5WkT4gRIevUiReBqCS16MUuTZsANUQD7UD_fmbXz2408KTr07Sj31QQxhKPFGSXFSuOBiZnxe3dzt_nwc='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXGtMzf_Ccu3nfeADyxqCspud-JWY5axIU-AG3Y_8z3ygbC1VP3hCASBWMDZVI1oHnGJ5WkT4gRIevUiReBqCS16MUuTZsANUQD7UD_fmbXz2408KTr07Sj31QQxhKPFGSXFSuOBiZnxe3dzt_nwc='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJaZwi-inpS9CofGWZ6IIafAg30f3JIVq3xKMZuvG2XYS7zhLJC965wkn6Q9WE9RZbISiBKEaCeHLWMXM-Ci2S7I8T-bETJuFJY-titNQ_D4QVHkbGv-9Q11tgbJ9fz6H9i1r5QJxDZUq9OzCvP3-fnNwFyHIkxWtT22idt_cxRCIRwM_Ja5fh9XCF6izaUX8qW6QM6oaAQOumdZCqpDhpERThfTC23MqcaHruoucZ'}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHT5S6zAMO13oIgFISkUZzDC8hPtMHqrlhDyv3BHu8J6UyfcleYFtgyFhAA2YyBdf66LyciuhmjU_OhjRCb0xCm438Q94fWbM6r3mhOFeB_xCGsTdVek7LPIXzJbxh_tTUg1NLYPWyLvc50IHE='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFNcoAhlY5nwwpbm2wSXjb8Tt3mVEqKNsJ8mlGOrzdV2Id_-uVHy15AYc78ozfTQW2xfWVzFPmhA51klhfzf-VehQ14MtEQCFGLGySxzK2nGDaVjewoUhVRhVyz3v8_kdg38QdxTr-vmdf8TMp_paKyy6hfB7EGG5UnnX6DiaBi'}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJaZwi-inpS9CofGWZ6IIafAg30f3JIVq3xKMZuvG2XYS7zhLJC965wkn6Q9WE9RZbISiBKEaCeHLWMXM-Ci2S7I8T-bETJuFJY-titNQ_D4QVHkbGv-9Q11tgbJ9fz6H9i1r5QJxDZUq9OzCvP3-fnNwFyHIkxWtT22idt_cxRCIRwM_Ja5fh9XCF6izaUX8qW6QM6oaAQOumdZCqpDhpERThfTC23MqcaHruoucZ'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFNcoAhlY5nwwpbm2wSXjb8Tt3mVEqKNsJ8mlGOrzdV2Id_-uVHy15AYc78ozfTQW2xfWVzFPmhA51klhfzf-VehQ14MtEQCFGLGySxzK2nGDaVjewoUhVRhVyz3v8_kdg38QdxTr-vmdf8TMp_paKyy6hfB7EGG5UnnX6DiaBi'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFNcoAhlY5nwwpbm2wSXjb8Tt3mVEqKNsJ8mlGOrzdV2Id_-uVHy15AYc78ozfTQW2xfWVzFPmhA51klhfzf-VehQ14MtEQCFGLGySxzK2nGDaVjewoUhVRhVyz3v8_kdg38QdxTr-vmdf8TMp_paKyy6hfB7EGG5UnnX6DiaBi'}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEE631yEQJcb3kob5asplmv1r66AEezqBb-X9dtD_WUmjXMIqHI40JGQpo6guBWbFMs23w--Irc_T4XbPf-8_iYGGPRlOOakAlftDY74qdOtRcyMkr53YzdQqzG'}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGVe9ZMyx3XnShHnZIx_0xVXcMw6wCwGYq1FW0cOw-Ock6HP-dIerMcWEwYqKVcgnGSiDxHcdydyu7c6xPXv7avTDzQ_03ipyqJfaFzg_Vqvi5_K-jCMFs8c-RKakI='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGVe9ZMyx3XnShHnZIx_0xVXcMw6wCwGYq1FW0cOw-Ock6HP-dIerMcWEwYqKVcgnGSiDxHcdydyu7c6xPXv7avTDzQ_03ipyqJfaFzg_Vqvi5_K-jCMFs8c-RKakI='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEE631yEQJcb3kob5asplmv1r66AEezqBb-X9dtD_WUmjXMIqHI40JGQpo6guBWbFMs23w--Irc_T4XbPf-8_iYGGPRlOOakAlftDY74qdOtRcyMkr53YzdQqzG'}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGVe9ZMyx3XnShHnZIx_0xVXcMw6wCwGYq1FW0cOw-Ock6HP-dIerMcWEwYqKVcgnGSiDxHcdydyu7c6xPXv7avTDzQ_03ipyqJfaFzg_Vqvi5_K-jCMFs8c-RKakI='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEE631yEQJcb3kob5asplmv1r66AEezqBb-X9dtD_WUmjXMIqHI40JGQpo6guBWbFMs23w--Irc_T4XbPf-8_iYGGPRlOOakAlftDY74qdOtRcyMkr53YzdQqzG'}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGVe9ZMyx3XnShHnZIx_0xVXcMw6wCwGYq1FW0cOw-Ock6HP-dIerMcWEwYqKVcgnGSiDxHcdydyu7c6xPXv7avTDzQ_03ipyqJfaFzg_Vqvi5_K-jCMFs8c-RKakI='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEE631yEQJcb3kob5asplmv1r66AEezqBb-X9dtD_WUmjXMIqHI40JGQpo6guBWbFMs23w--Irc_T4XbPf-8_iYGGPRlOOakAlftDY74qdOtRcyMkr53YzdQqzG'}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'machinelearningmastery', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcR7PUQnxMY6JAPTUHq-qg5YcjyPiX3RkZK5pa_o71HJ_htNBm6rhH60xFhIhYl_btL58gI5IXGTlL4O1Hb4aG-39g9rNvhHARhuruh6FUMu9RXyXzx_FigJyYfZr7rI1w-7jVfAmhZ2-WDfteBxXFnQ2JfV0YvaeCbSnHWJv6N2GMFoiJpLCF-wuaoL8sH-nRoImMvlwmtX9soIk='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFNcoAhlY5nwwpbm2wSXjb8Tt3mVEqKNsJ8mlGOrzdV2Id_-uVHy15AYc78ozfTQW2xfWVzFPmhA51klhfzf-VehQ14MtEQCFGLGySxzK2nGDaVjewoUhVRhVyz3v8_kdg38QdxTr-vmdf8TMp_paKyy6hfB7EGG5UnnX6DiaBi'}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHT5S6zAMO13oIgFISkUZzDC8hPtMHqrlhDyv3BHu8J6UyfcleYFtgyFhAA2YyBdf66LyciuhmjU_OhjRCb0xCm438Q94fWbM6r3mhOFeB_xCGsTdVek7LPIXzJbxh_tTUg1NLYPWyLvc50IHE='}, {'label': 'readthedocs', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGDGrpPzrlTEWy37WpDoB8Do2rp6UB0ECPOUTQhvXV4wG9AJjq6uaLZFsHM1RuMyqh8cYMt68N3nw-gxwQ84h9dZ6ymSXGVuf-z_7HRyaBaYodpIYUpO2cMvitngiBDT6lpA=='}, {'label': 'mlexpert', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHT5S6zAMO13oIgFISkUZzDC8hPtMHqrlhDyv3BHu8J6UyfcleYFtgyFhAA2YyBdf66LyciuhmjU_OhjRCb0xCm438Q94fWbM6r3mhOFeB_xCGsTdVek7LPIXzJbxh_tTUg1NLYPWyLvc50IHE='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0k5LEt26cW0Uf3VuWfmQ1BHsZNRP38yDu-5O382B-qVwbLNz2WBja8G1QZs6QdhcvXYTmIrWYhnHVzSWA8Bct3zB4tW1VVSMebLX75usM4hJEhcQZXAm6ANstyrDfw59Li7cbG-VOYNHBqnsA0XofkbyXoqlAgpoBJrtWPGr5ottdGlr-Gqi3LWzX8tI-0fc7OHP8qg=='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHzfkSdah7lvVkCONdZ0ZVY4Txn6jRHtK_2CaUeBZdiqPmL63jVxDa7UdXQjfF2_XktFivtsS14miGjIzkT73QZZaRjsFKixNYzI8IzQXwgMB5Qi-FSLhd6eWDOxzvtqDkAPAe35w=='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/1-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHzfkSdah7lvVkCONdZ0ZVY4Txn6jRHtK_2CaUeBZdiqPmL63jVxDa7UdXQjfF2_XktFivtsS14miGjIzkT73QZZaRjsFKixNYzI8IzQXwgMB5Qi-FSLhd6eWDOxzvtqDkAPAe35w=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEJKtusBLmdtd_TxlMUdOmYWAQKBghC9KyzJQu0d-DMuWAacXKvAR_gflljMCTQkHM-Mvy2rrnUnrXoKnA7TtL7tQCJdMfatKfD6AyIWjDHNdjDHIzv2UyQoO2dObdJr3qKdCf3wHJ0DJw3GMkALT_wuJuYN7bivczwntadLEDnNvHkwOPzLA3iVxrFyjoD9NUFTc0ZSv56zdYNInIXeIQaSs57EkQRrMM88xUZFnYMobLBN1WNg9rNsy0UCw=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFnc7mZBslfqgXI6F1DIOTTZgCJqjZlT00h1eq1BHl_rotxVZ6y4xhF4bFCEH_NyJ7LUe4mjC9L7cwsJ0BIZKihIlG5ZX8KTTUIWcHcMcOyEk1kgSqA_Ye1uHBTfaBg4dmSojT2yTA='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETkOsIoKQJg-bI35FahaUcFSoP7fdWo-yQx7TR94rpm48CJxQ_vF2XNdIoPGmFpI9a0wl2slVOsw0O45T2WWEunj5dt6uOfdKifbS7GPHKGBok3D0vLbCGIzXGJy-GrkLmpF-n_lo='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETkOsIoKQJg-bI35FahaUcFSoP7fdWo-yQx7TR94rpm48CJxQ_vF2XNdIoPGmFpI9a0wl2slVOsw0O45T2WWEunj5dt6uOfdKifbS7GPHKGBok3D0vLbCGIzXGJy-GrkLmpF-n_lo='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFnc7mZBslfqgXI6F1DIOTTZgCJqjZlT00h1eq1BHl_rotxVZ6y4xhF4bFCEH_NyJ7LUe4mjC9L7cwsJ0BIZKihIlG5ZX8KTTUIWcHcMcOyEk1kgSqA_Ye1uHBTfaBg4dmSojT2yTA='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFnc7mZBslfqgXI6F1DIOTTZgCJqjZlT00h1eq1BHl_rotxVZ6y4xhF4bFCEH_NyJ7LUe4mjC9L7cwsJ0BIZKihIlG5ZX8KTTUIWcHcMcOyEk1kgSqA_Ye1uHBTfaBg4dmSojT2yTA='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETkOsIoKQJg-bI35FahaUcFSoP7fdWo-yQx7TR94rpm48CJxQ_vF2XNdIoPGmFpI9a0wl2slVOsw0O45T2WWEunj5dt6uOfdKifbS7GPHKGBok3D0vLbCGIzXGJy-GrkLmpF-n_lo='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETkOsIoKQJg-bI35FahaUcFSoP7fdWo-yQx7TR94rpm48CJxQ_vF2XNdIoPGmFpI9a0wl2slVOsw0O45T2WWEunj5dt6uOfdKifbS7GPHKGBok3D0vLbCGIzXGJy-GrkLmpF-n_lo='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETkOsIoKQJg-bI35FahaUcFSoP7fdWo-yQx7TR94rpm48CJxQ_vF2XNdIoPGmFpI9a0wl2slVOsw0O45T2WWEunj5dt6uOfdKifbS7GPHKGBok3D0vLbCGIzXGJy-GrkLmpF-n_lo='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFnc7mZBslfqgXI6F1DIOTTZgCJqjZlT00h1eq1BHl_rotxVZ6y4xhF4bFCEH_NyJ7LUe4mjC9L7cwsJ0BIZKihIlG5ZX8KTTUIWcHcMcOyEk1kgSqA_Ye1uHBTfaBg4dmSojT2yTA='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'substack', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHtcUfeQi_4bbKr-OLYL_I0dgsV_xcdX5w-eZmnCKlM-goCz1W-mIi25hhW7PVVe46gI8RGnWz4ALBp3be4DcOUlp4ETKEsFIPKte8KBviWB4N7nuClLSUCicCGzKtMVOtgrHkQ3v0EjfzuzTHTT_P79pxlQyUJfEnh2ac713ayHYw7PJu9QA=='}, {'label': 'substack', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHtcUfeQi_4bbKr-OLYL_I0dgsV_xcdX5w-eZmnCKlM-goCz1W-mIi25hhW7PVVe46gI8RGnWz4ALBp3be4DcOUlp4ETKEsFIPKte8KBviWB4N7nuClLSUCicCGzKtMVOtgrHkQ3v0EjfzuzTHTT_P79pxlQyUJfEnh2ac713ayHYw7PJu9QA=='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'collabnix', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFZv5c8ZYnrhjOzhI_DSK-1VEg8957MkkJaxAM-2QqiBLoVQ886QyKHhjMQMyPF7XSfO6rXIyzaTouhv-fIQfCtONGDqp1moRb6V2ImDDV5v0mIyKBTt4FkicCSlCNQlhZPo9rroIX5SzUSWT8ar-gx92uK2eKum8YtTEKwPtydfrCpzqD3lq_6mW4yZQ=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEJKtusBLmdtd_TxlMUdOmYWAQKBghC9KyzJQu0d-DMuWAacXKvAR_gflljMCTQkHM-Mvy2rrnUnrXoKnA7TtL7tQCJdMfatKfD6AyIWjDHNdjDHIzv2UyQoO2dObdJr3qKdCf3wHJ0DJw3GMkALT_wuJuYN7bivczwntadLEDnNvHkwOPzLA3iVxrFyjoD9NUFTc0ZSv56zdYNInIXeIQaSs57EkQRrMM88xUZFnYMobLBN1WNg9rNsy0UCw=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'substack', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHtcUfeQi_4bbKr-OLYL_I0dgsV_xcdX5w-eZmnCKlM-goCz1W-mIi25hhW7PVVe46gI8RGnWz4ALBp3be4DcOUlp4ETKEsFIPKte8KBviWB4N7nuClLSUCicCGzKtMVOtgrHkQ3v0EjfzuzTHTT_P79pxlQyUJfEnh2ac713ayHYw7PJu9QA=='}, {'label': 'substack', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHtcUfeQi_4bbKr-OLYL_I0dgsV_xcdX5w-eZmnCKlM-goCz1W-mIi25hhW7PVVe46gI8RGnWz4ALBp3be4DcOUlp4ETKEsFIPKte8KBviWB4N7nuClLSUCicCGzKtMVOtgrHkQ3v0EjfzuzTHTT_P79pxlQyUJfEnh2ac713ayHYw7PJu9QA=='}, {'label': 'substack', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHtcUfeQi_4bbKr-OLYL_I0dgsV_xcdX5w-eZmnCKlM-goCz1W-mIi25hhW7PVVe46gI8RGnWz4ALBp3be4DcOUlp4ETKEsFIPKte8KBviWB4N7nuClLSUCicCGzKtMVOtgrHkQ3v0EjfzuzTHTT_P79pxlQyUJfEnh2ac713ayHYw7PJu9QA=='}, {'label': 'substack', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHtcUfeQi_4bbKr-OLYL_I0dgsV_xcdX5w-eZmnCKlM-goCz1W-mIi25hhW7PVVe46gI8RGnWz4ALBp3be4DcOUlp4ETKEsFIPKte8KBviWB4N7nuClLSUCicCGzKtMVOtgrHkQ3v0EjfzuzTHTT_P79pxlQyUJfEnh2ac713ayHYw7PJu9QA=='}, {'label': 'elightwalk', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx0h-4_cQjgi6mOKxwm-MiOcmpr9_hZmXIebD35ZP4mBomDqWFKiTAPRHDG8njC-3OpWuc-zrSOaOx-PCMeiqNnl_KRfn14RkPZS-hqSIJNUDDDqmvbUb7bM6W2yirBtwu0b-u7o39JkeMRZs1KeQ='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF50mjm212CvIxT3DsEBED9I4fE4F9UkdOCDB7nLbs5wE9SxjPwcDgB0QEMFgIAuqycubCC5GutGE-Ch4BE1YT_NVetcSIPwdYXxXV0krIxJfidHLN9R9fLQCVw05cFae-YbDQQuG4aUSVrj4rtIiNf6b3BBF5Km3Zq9vxZKs5Y720Pwt7ceM157jF04STqixjTrQ39a1Q='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF50mjm212CvIxT3DsEBED9I4fE4F9UkdOCDB7nLbs5wE9SxjPwcDgB0QEMFgIAuqycubCC5GutGE-Ch4BE1YT_NVetcSIPwdYXxXV0krIxJfidHLN9R9fLQCVw05cFae-YbDQQuG4aUSVrj4rtIiNf6b3BBF5Km3Zq9vxZKs5Y720Pwt7ceM157jF04STqixjTrQ39a1Q='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/2-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF50mjm212CvIxT3DsEBED9I4fE4F9UkdOCDB7nLbs5wE9SxjPwcDgB0QEMFgIAuqycubCC5GutGE-Ch4BE1YT_NVetcSIPwdYXxXV0krIxJfidHLN9R9fLQCVw05cFae-YbDQQuG4aUSVrj4rtIiNf6b3BBF5Km3Zq9vxZKs5Y720Pwt7ceM157jF04STqixjTrQ39a1Q='}, {'label': 'ollama', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGn0NJkJG8bM2-zpfetPTY2FWd8foOluCHyD3Xns8eA3pKc-CWAHFIPC_4PslMsE7KJt08hz2xln-8nuKL0hFxvCirO8m1hTmQWlIuZsbZprdYi6nosukB7scTAgj1HQf-cnlxg'}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH1uwuZP087XRXxJggVIGVFGcOrbfX1XtE6UA4eNna3rHd0la7os1oQH-Rq9mQts_UFyPF9_53jxBbzzliNLkJaDlG1-Czz3qAzy4cWbl-1I8XMnqNDsKFicNgiZuP-sHIXy45drdyBoSewZmWisEh4uKXDCkTQW5jLVFMXtcXBAUq6vK7StJEfiehZVJQ-MPpc0-M='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH1uwuZP087XRXxJggVIGVFGcOrbfX1XtE6UA4eNna3rHd0la7os1oQH-Rq9mQts_UFyPF9_53jxBbzzliNLkJaDlG1-Czz3qAzy4cWbl-1I8XMnqNDsKFicNgiZuP-sHIXy45drdyBoSewZmWisEh4uKXDCkTQW5jLVFMXtcXBAUq6vK7StJEfiehZVJQ-MPpc0-M='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEWsB_z7peGnk73OxZaeAUhD68UPq4WDp8XV6zXvwEzG4t1PGU_A8fajq-SiGKHwRhRS2DCR3MB5a7QujYa71P8EFA99pVUCENNeQd_c6MqsKtMZV4fzAuEr9gSvJKQL59heia0sLM='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6yvdgp-pRgoGkps7xaQET-NOY03Ae09jYHjWzWlmXHyXOu7zZTx3D2xVCod9SCDHY25nAsayEG-9SLAxjNOtoU2m4fY_iUKvJ-LPAKwTWSn9Y0JEempAxUGZ0vYFtin6N6HDMSg6Xit0CWr7I67JqXbRwqcsZS7xHrVe4MgfRy0NGvQ9YV1WeZjQgJ7vtAg2yqEK3iY6FAF8='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6yvdgp-pRgoGkps7xaQET-NOY03Ae09jYHjWzWlmXHyXOu7zZTx3D2xVCod9SCDHY25nAsayEG-9SLAxjNOtoU2m4fY_iUKvJ-LPAKwTWSn9Y0JEempAxUGZ0vYFtin6N6HDMSg6Xit0CWr7I67JqXbRwqcsZS7xHrVe4MgfRy0NGvQ9YV1WeZjQgJ7vtAg2yqEK3iY6FAF8='}, {'label': 'peddals', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFAlKmPHp29QgYH444XO57zq5h4MYvj52FTiE-Py-eMzlreqRtybbWSLhvzgZtVhRcifOaOFpMkuKD6BfbIvyb6ep0MNDgNVrvCKWoygLHbGg3TZLEkHgKLPghlcZBLSGETvJH0zJDIW0jJKkSft_DXie_H26YYPrOrk4A='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFEAQSOwMiXirZCHgTPKMuPPuU6_HlhsVga9b-c5Xdho1sHXNRszognaV0R-NCcegei-yikjVSm8FstMZQDrInvIn4rBAPwHK_oKgPFb5QEltAxMroKgw5owBYE5WssWYGt3p5CbQzEDIEegyDRBaLBngdf6WGknIcriLSAJO_tYn99GwN3u4l0j2_gWIJJA6SnRVv8L0g='}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'reddit', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFEAQSOwMiXirZCHgTPKMuPPuU6_HlhsVga9b-c5Xdho1sHXNRszognaV0R-NCcegei-yikjVSm8FstMZQDrInvIn4rBAPwHK_oKgPFb5QEltAxMroKgw5owBYE5WssWYGt3p5CbQzEDIEegyDRBaLBngdf6WGknIcriLSAJO_tYn99GwN3u4l0j2_gWIJJA6SnRVv8L0g='}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'broadcom', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHB70aiyV9CKvKBXxYPvQYsY2LeUvItpAX19-6G0_lY7ZJxyKw1PzP8FfvPFm4s2scrg_jkANrZMpTAwfyMhCOSJG-egxC3v29mOxlcm2VhURvcBFnlwY_-NK9Off_hxhRcXGvceoEkupMF15JFg9wfBnsuEx5DRAaGdYyuXntzODg7y0jbWDYpyN0Aa05WvVjKBmbmGc45E2skf-vxobaoWhWXy7NPrYUbvmidY6XVqNDL7fEEKQl4hGtmQElYjHTbOjgAl_Gbm45GtkdEb2n5wrmHgBg1B4xis7ud-8Bqrbv1-dwYMH0='}, {'label': 'peddals', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFAlKmPHp29QgYH444XO57zq5h4MYvj52FTiE-Py-eMzlreqRtybbWSLhvzgZtVhRcifOaOFpMkuKD6BfbIvyb6ep0MNDgNVrvCKWoygLHbGg3TZLEkHgKLPghlcZBLSGETvJH0zJDIW0jJKkSft_DXie_H26YYPrOrk4A='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH1uwuZP087XRXxJggVIGVFGcOrbfX1XtE6UA4eNna3rHd0la7os1oQH-Rq9mQts_UFyPF9_53jxBbzzliNLkJaDlG1-Czz3qAzy4cWbl-1I8XMnqNDsKFicNgiZuP-sHIXy45drdyBoSewZmWisEh4uKXDCkTQW5jLVFMXtcXBAUq6vK7StJEfiehZVJQ-MPpc0-M='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6yvdgp-pRgoGkps7xaQET-NOY03Ae09jYHjWzWlmXHyXOu7zZTx3D2xVCod9SCDHY25nAsayEG-9SLAxjNOtoU2m4fY_iUKvJ-LPAKwTWSn9Y0JEempAxUGZ0vYFtin6N6HDMSg6Xit0CWr7I67JqXbRwqcsZS7xHrVe4MgfRy0NGvQ9YV1WeZjQgJ7vtAg2yqEK3iY6FAF8='}, {'label': 'anakin', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFK4eAwoaw8RFilqQ46XpPVpgFQMiL0Pp8A6AvopzzoJvQmau5Ee1-2HSS9CT1JxFO3hQ3xiKSDmuk-qr4YEsFkl3z2DX_aWdybM4wFZ0cQpXa51d00KPWmYsytrhG9t0Qwzs18zcD8BlPDvg=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'anakin', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFK4eAwoaw8RFilqQ46XpPVpgFQMiL0Pp8A6AvopzzoJvQmau5Ee1-2HSS9CT1JxFO3hQ3xiKSDmuk-qr4YEsFkl3z2DX_aWdybM4wFZ0cQpXa51d00KPWmYsytrhG9t0Qwzs18zcD8BlPDvg=='}, {'label': 'anakin', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFK4eAwoaw8RFilqQ46XpPVpgFQMiL0Pp8A6AvopzzoJvQmau5Ee1-2HSS9CT1JxFO3hQ3xiKSDmuk-qr4YEsFkl3z2DX_aWdybM4wFZ0cQpXa51d00KPWmYsytrhG9t0Qwzs18zcD8BlPDvg=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'anakin', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFK4eAwoaw8RFilqQ46XpPVpgFQMiL0Pp8A6AvopzzoJvQmau5Ee1-2HSS9CT1JxFO3hQ3xiKSDmuk-qr4YEsFkl3z2DX_aWdybM4wFZ0cQpXa51d00KPWmYsytrhG9t0Qwzs18zcD8BlPDvg=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-10', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGK2fj87pAm7B2gdVx-dAj-7Z2zSF5NiWevM_NuuI8z1Lr-5Q21lOOWVrPUj4Y1rTSMM89Sdm8toX34Q_Jp7B5cmAaV_JzqU6sK8gbd-0ohv6vRxxbk1nFtsWjggct81ns5w7IceUYTujWfAwFl30awhhelx2KgStRHEY9olCkR'}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH1uwuZP087XRXxJggVIGVFGcOrbfX1XtE6UA4eNna3rHd0la7os1oQH-Rq9mQts_UFyPF9_53jxBbzzliNLkJaDlG1-Czz3qAzy4cWbl-1I8XMnqNDsKFicNgiZuP-sHIXy45drdyBoSewZmWisEh4uKXDCkTQW5jLVFMXtcXBAUq6vK7StJEfiehZVJQ-MPpc0-M='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6yvdgp-pRgoGkps7xaQET-NOY03Ae09jYHjWzWlmXHyXOu7zZTx3D2xVCod9SCDHY25nAsayEG-9SLAxjNOtoU2m4fY_iUKvJ-LPAKwTWSn9Y0JEempAxUGZ0vYFtin6N6HDMSg6Xit0CWr7I67JqXbRwqcsZS7xHrVe4MgfRy0NGvQ9YV1WeZjQgJ7vtAg2yqEK3iY6FAF8='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH6yvdgp-pRgoGkps7xaQET-NOY03Ae09jYHjWzWlmXHyXOu7zZTx3D2xVCod9SCDHY25nAsayEG-9SLAxjNOtoU2m4fY_iUKvJ-LPAKwTWSn9Y0JEempAxUGZ0vYFtin6N6HDMSg6Xit0CWr7I67JqXbRwqcsZS7xHrVe4MgfRy0NGvQ9YV1WeZjQgJ7vtAg2yqEK3iY6FAF8='}, {'label': 'medium', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEgyQ7_XMvNIrFJ_73kMwQJEsopn4sQIr40BrePP_B_APKXQ6Vrp14oXyH_oMdV57WlLfYJxeTVMkgDM1vRYn4sybNLGNYnmUrGPbGaugPUIxk-8TK0WB1jeL0_87o-0Lttxz_avi2fHEH04o0mHigSkNFx90za2BIYat37oQvOaQYfXvsjyftVCkyNV0XKp9rk1QQihBZXjTHybVuWlrg2vHME'}, {'label': 'arsturn', 'short_url': 'https://vertexaisearch.cloud.google.com/id/3-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEP7pfDjfTIwQhPCsyvVzYRm48dXQHZxjKFU_SLsjq0uFzejFVnIL7ViqSS765pVn26HG542qyDpP54ieUBl6orVGOajxvZ4SgV7XMFS8ZiyY6QoaGmdz93EmyhNB7LZNZXU6gAC8VWURzTLgYlQ2Q66Avo34FwZfQ1zdz9kFwzzbxB16a4KQ=='}], 'initial_search_query_count': 3, 'max_research_loops': 3, 'research_loop_count': 2}